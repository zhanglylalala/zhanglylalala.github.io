<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/avatar.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/avatar.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://http://www.laughingtree.cn').hostname,
    root: '/',
    scheme: 'Mist',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":true},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="ISPC (Intel SPMD Program Compiler)Format of ISPC ISPC is an SPMD compiler, not an SIMD.   The code that need to be paralleled will be written in a file with surfix of “.ispc” as a function. And we wil">
<meta property="og:type" content="article">
<meta property="og:title" content="02. Parallel programming models">
<meta property="og:url" content="http://http//www.laughingtree.cn/2022/04/18/02-Parallel-programming-models/index.html">
<meta property="og:site_name" content="LaughingTree">
<meta property="og:description" content="ISPC (Intel SPMD Program Compiler)Format of ISPC ISPC is an SPMD compiler, not an SIMD.   The code that need to be paralleled will be written in a file with surfix of “.ispc” as a function. And we wil">
<meta property="article:published_time" content="2022-04-18T03:53:04.000Z">
<meta property="article:modified_time" content="2022-05-03T07:40:40.444Z">
<meta property="article:author" content="LiyunZhang">
<meta property="article:tag" content="并行计算与分布式">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://http//www.laughingtree.cn/2022/04/18/02-Parallel-programming-models/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>02. Parallel programming models | LaughingTree</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">LaughingTree</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags<span class="badge">29</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories<span class="badge">33</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="Searching..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2022/04/18/02-Parallel-programming-models/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          02. Parallel programming models
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-18 11:53:04" itemprop="dateCreated datePublished" datetime="2022-04-18T11:53:04+08:00">2022-04-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-05-03 15:40:40" itemprop="dateModified" datetime="2022-05-03T15:40:40+08:00">2022-05-03</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index">
                    <span itemprop="name">计算机科学与技术</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-CMU-15-418-Stanford-CS149/" itemprop="url" rel="index">
                    <span itemprop="name">并行计算 (CMU 15-418 / Stanford CS149)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="ISPC-Intel-SPMD-Program-Compiler"><a href="#ISPC-Intel-SPMD-Program-Compiler" class="headerlink" title="ISPC (Intel SPMD Program Compiler)"></a>ISPC (Intel SPMD Program Compiler)</h1><h2 id="Format-of-ISPC"><a href="#Format-of-ISPC" class="headerlink" title="Format of ISPC"></a>Format of ISPC</h2><ol>
<li><p>ISPC is an SPMD compiler, not an SIMD. </p>
</li>
<li><p>The code that need to be paralleled will be written in a file with surfix of “.ispc” as a function. And we will call that function in the main.cpp.<br>Call to ISPC function spawns gang of ISPC program instances. All instances run ISPC code concurrently. The ISPC function will return when all instances have completed.<br>All code in main.cpp will be executed sequentially. </p>
</li>
<li><p><code>programCount</code>: the number of simultaneously executing instances in the gang. It is the same for all instances, thus called “uniform value”. This is not set by programmer, but by the run-time system. programmer can only read it but don’t set that. </p>
</li>
<li><p><code>programIndex</code>: the ID of the current instance in the gang. It is a non-uniform value, namely varying.<br>This is used to assign work to each instance. If we don’t use the programIndex to control the work to be done by each instance, they will all do all the work. Thus there will be redundant and have no performance improve. </p>
</li>
<li><p><code>uniform</code>: a type modifier. All instances have a copy of the same value for this variable. Its use is purely an optimization. Not needed for correctness.<br>We cannot add a non-uniform value to a uniform value directly, which will cause a compile-time type error. In order to do so, we need a reduce_add function from ISPC library. </p>
</li>
<li><p>Those ISPC program instances is not separate threads. The ISPC complier actually generates an SIMD thread. So the programCount is the vector width of the machine.<br>So it can only run on one core. And “task” is used to achieve multi-core execution.</p>
</li>
</ol>
<h2 id="Ways-of-assignment"><a href="#Ways-of-assignment" class="headerlink" title="Ways of assignment"></a>Ways of assignment</h2><ol>
<li><p>Interleaved assignment: the data processed by each instance is discontinuous, namely the subsctipt is: </p>
<script type="math/tex; mode=display">programIndex+i\times programCount,i\in[0,\frac{N-programIndex}{programCount})</script></li>
<li><p>Block assignment: the data is split into several chunks, and each instance process one chunk. So the data is continuous, namely the subscript is: </p>
<script type="math/tex; mode=display">programIndex\times count+i, i\in[0,count),count=\frac{N}{programCount}</script></li>
<li><p>When using the block assignment, there might exist some situation when the cost of processing later data is more expensive than processing former data, which will make the assignment uneven. So the interleaved assignment is less risky. </p>
</li>
<li><p>Since ISPC only generate one thread, the continuous access of data in block assignment is not more cache-friend then the discontinuous access in interleaved assignment.<br>If there are several threads, than block assignment might be more cache-friend. </p>
</li>
<li><p>The data requested by all instances at the same time is a vector. In interleaved assignment, the data in a vector is memory continuous, while it is not in block assignment. So in memory access, interleaved assignment is faster. </p>
</li>
<li><p><code>foreach (i = 0 ... N)</code> says that these loop iterations can be paralleled, and ISPC implementation assigns iterations to program instances in gang. Current ISPC implementation will perform a static interleaved assignment</p>
</li>
</ol>
<h2 id="System-layers"><a href="#System-layers" class="headerlink" title="System layers"></a>System layers</h2><ol>
<li><p>The layers from up to down is that parallel applications, compilers and/or parallel runtime, operating system, Micro-architecture (hardware implementation)</p>
</li>
<li><p>Different parallel models can have different combinations of concerned layers. </p>
</li>
<li><p>If we express parallelism with pthread, it goes through all layers. First the parallel application calls <code>pthread_create()</code> to access pthread library implementation. Then the pthread library uses <code>System call API</code> to ask OS support: kernel thread management. Finally, the OS uses <code>x86-64</code> to control modern multi-core CPU. </p>
</li>
<li><p>If we express parallelism with ISPC without “task”, it doesn’t need the support of OS. The parallel application uses ISPC language to ask for service of ISPC compiler. And the complier will produce machine language of x86-64 including <code>AVX vector instruction</code> to control a single-core of CPU. </p>
</li>
</ol>
<h1 id="Communication"><a href="#Communication" class="headerlink" title="Communication"></a>Communication</h1><h2 id="Shared-Address-Space"><a href="#Shared-Address-Space" class="headerlink" title="Shared Address Space"></a>Shared Address Space</h2><ol>
<li><p>The whole machine has a common space address. When threads aren’t working together, they just access their memory space. They can communicate with each by reading or writing the same data and manipulating synchronization primitives (like locks)</p>
</li>
<li><p>This model requires hardware support to implement efficiently. In hardware implementation, any processor can directly reference any memory location</p>
</li>
<li><p>Symmetric (shared-memory) multi-processor (SMP): all processors have uniform memory access time, namely the cost of accessing an uncached memory address is the same for all processors<br>This is unscalarable since the access latency will increase fast with more and more processors and memory chips.<br>The cores can share memory through a shared L3 cahce or a crossbar switch with die area of one core</p>
</li>
<li><p>Non-uniform memory access (NUMA): All processors can access any memory location, but the cost of memory access (latency and/or bandwidth) is different for different processors. Each processor has a memory chip that is close to it.<br>This is more scalarable since the low latency and high bandwidth to local memory.<br>Cost is the increased programmer effort for performance tuning. Finding, exploiting locality is important to performance (want most memory accesses to be to local memories)</p>
</li>
</ol>
<h2 id="Message-Passing"><a href="#Message-Passing" class="headerlink" title="Message Passing"></a>Message Passing</h2><ol>
<li><p>Threads operate within their own private address spaces, and they communicate by sending/receiving messages</p>
</li>
<li><p>send: specifies recipient, buffer to be transmitted, and optional message identifier (“tag”)<br>receive: sender, specifies buffer to store data, and optional message identifier</p>
</li>
<li><p>With this model, we can easily build large scale of parallel machine by just interconnect them together. Hardware need not implement system-wide loads and stores to execute message passing programs, need only be able to communicate messages<br>But the interconnect speed can be the bottleneck of the system. </p>
</li>
<li><p>We can implement the message passing model with shared memory space.<br>Sending message is copying memory from message library buffers, while receiving message is copying data from message library buffers</p>
</li>
<li><p>We can also implement shared address space abstraction on machines that do not support it in hardware via less efficient software solution.<br>Mark all pages with shared variables as invalid at first, and page-fault handler issues appropriate network requests</p>
</li>
<li><p>Synchronous (blocking) send and receive<br>Send(): call returns when sender receives acknowledgement that message data resides in address space of receiver<br>Recv(): call returns when data from received message is copied into address space of receiver and acknowledgement sent back to sender<br>So when using message passing model, we need to be careful for the order of send() and recv() in each threads because it may easily raise a deadlock.<br>If the first call of all threads is send(), then no one is receiving and all is waiting someone to receive what they have sent.<br>One common way to program is to arrage one thread to send first and the receiver of that send to receive first. </p>
</li>
<li><p>Non-blocking asynchronous send/recv<br>Send() call returns immediately, while recv() posts intent to receive in the future and returns immediately.<br>We can use checksend(), checkrecv() to determine actual status of send/receipt.<br>Buffer provided to send() cannot be modified by calling thread since message processing occurs concurrently with thread execution</p>
</li>
</ol>
<h2 id="Data-Parallel"><a href="#Data-Parallel" class="headerlink" title="Data Parallel"></a>Data Parallel</h2><ol>
<li><p>Data parallel has a very rigid computation struture. If it works well, it will work very well. But sometimes it just won’t work. </p>
</li>
<li><p>Nowadays, data parallel usually takes the form of SPMD instead of SIMD. Programs perform same function on different data elements in a collection<br><code>map(function, collection)</code>: Synchronization is implicit at the end of the map. Map returns when function has been applied to all elements ofcollection</p>
</li>
<li><p>When the function is too complicated, the result might be non-deterministic.<br>Data-parallel model (foreach) provides no specification of order in which iterations occur and no primitives for fine-grained mutual exclusion/synchronization.</p>
</li>
<li><p>Streams: collections of elements. Elements can be processed independently.<br>Kernels: side-effect-free functions. Operate element-wise on collections. </p>
</li>
<li><p>A stream can be claimed by <code>stream&lt;ElemType&gt; name(N)</code><br>When define the kernel function, its parameters are single elements instead of a whole collection. But when call the kernel function, we pass the streams into the function directly. </p>
</li>
<li><p>Benefits of stream programming:<br>Functions really are side-effect free (cannot write a non-deterministic program)<br>Program data flow is known by compiler: Inputs and outputs of each invocation are known in advance and thus prefetching can be employed to hide latency.<br>When there are multiple kernels, and the output of the last kernel is the input of the next kernel, producer-consumer locality is known in advance.<br>Implementation can be structured so outputs of first kernel are immediately processed by second kernel. The values are stored in on-chip buffers/caches and never written to memory, which saves bandwidth.<br>These optimizations are responsibility of stream program compiler. Requires global program analysis.</p>
</li>
<li><p>Drawback of stream programming: Need library of operators to describe complex data flows, so it might go wrong. </p>
</li>
<li><p><code>stream_gather(input, indices, tmp_input)</code>: Put elements in input to tmp_input according to indices. This is called before the kernel function, and the kernel function will deal with gathered stream.<br><code>stream_scatter(tmp_output, indices, output)</code>: Similar to stream_gather, but it is called after the kernel function, and kernel function will deal with original stream.<br>The parameters of both function are all stream. </p>
</li>
</ol>
<h2 id="Synchronization-and-Communication"><a href="#Synchronization-and-Communication" class="headerlink" title="Synchronization and Communication"></a>Synchronization and Communication</h2><ol>
<li><p>In shared address space, mutual exclusion is required for shared variables, and barriers are used to express dependencies between phases of computation.<br>They can communicate through implicit loads/stores to shared variables. </p>
</li>
<li><p>In message passing model, the synchronizations and communications are both performed by sending and receiving messages. </p>
</li>
<li><p>In data parallel model, a single logical thread is in control, but iterations of forall loop may be parallelized by the system. There is an implicit barrier at end offorallloop body.<br>They can also communicate throught implicit loads and stores, like shared address space. There is also some special built-in primitives for more complex communication patterns, e.g., reduce</p>
</li>
</ol>
<h2 id="Modern-practice"><a href="#Modern-practice" class="headerlink" title="Modern practice"></a>Modern practice</h2><ol>
<li><p>Use shared address space programming within a multi-core chip of a cluster, use message passing between chips<br>Use convenience of shared address space where it can be implemented efficiently (within a chip), require explicit communication elsewhere. </p>
</li>
<li><p>Data-parallel-ish programming models support shared-memory style synchronization primitives in kernels. This could permit limited forms of inter-iteration communication. </p>
</li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F/" rel="tag"><i class="fa fa-tag"></i> 并行计算与分布式</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/04/13/01-Modern-Multicore-Processors/" rel="prev" title="01. Modern Multicore Processors">
      <i class="fa fa-chevron-left"></i> 01. Modern Multicore Processors
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/04/20/03-Parallel-Programming-Basics/" rel="next" title="03. Parallel Programming Basics">
      03. Parallel Programming Basics <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#ISPC-Intel-SPMD-Program-Compiler"><span class="nav-number">1.</span> <span class="nav-text">ISPC (Intel SPMD Program Compiler)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Format-of-ISPC"><span class="nav-number">1.1.</span> <span class="nav-text">Format of ISPC</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Ways-of-assignment"><span class="nav-number">1.2.</span> <span class="nav-text">Ways of assignment</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#System-layers"><span class="nav-number">1.3.</span> <span class="nav-text">System layers</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Communication"><span class="nav-number">2.</span> <span class="nav-text">Communication</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Shared-Address-Space"><span class="nav-number">2.1.</span> <span class="nav-text">Shared Address Space</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Message-Passing"><span class="nav-number">2.2.</span> <span class="nav-text">Message Passing</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-Parallel"><span class="nav-number">2.3.</span> <span class="nav-text">Data Parallel</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Synchronization-and-Communication"><span class="nav-number">2.4.</span> <span class="nav-text">Synchronization and Communication</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Modern-practice"><span class="nav-number">2.5.</span> <span class="nav-text">Modern practice</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="LiyunZhang"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">LiyunZhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">223</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">33</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liyun Zhang</span>
</div>
<div class="BbeiAn-info">
       浙ICP备 -
    <a target="_blank" href="http://www.miitbeian.gov.cn/" style="color:#ffffff"  rel="nofollow">19047088号-1</a> <!--a标签中增加nofollow属性，避免爬虫出站。-->|
    <a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=33011802001835" style="color:#ffffff;text-decoration:none;padding-left:30px;background:url(https://s1.ax1x.com/2018/09/29/ilmwIH.png) no-repeat left center" rel="nofollow">浙公网安备 33011802001835号</a>      <!--这里将图标作为了背景，以使得能和后面的文字在同一行-->

</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

</body>
</html>
