<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/avatar.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/avatar.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://http://www.laughingtree.cn').hostname,
    root: '/',
    scheme: 'Mist',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":true},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="General When we say how many layers a network has, we mean how many layers in that network has weight. Namely, the sum of fully-connected layers and convolution layers.  The rule of naming a layer: &amp;e">
<meta property="og:type" content="article">
<meta property="og:title" content="07. CNN Architectures">
<meta property="og:url" content="http://http//www.laughingtree.cn/2020/04/09/07-CNN-Architectures/index.html">
<meta property="og:site_name" content="LaughingTree">
<meta property="og:description" content="General When we say how many layers a network has, we mean how many layers in that network has weight. Namely, the sum of fully-connected layers and convolution layers.  The rule of naming a layer: &amp;e">
<meta property="og:image" content="https://i.loli.net/2020/04/10/8uBvQ1gKk7wndIC.png">
<meta property="og:image" content="https://i.loli.net/2020/04/11/whfvrYcQHAlX9Gj.png">
<meta property="og:image" content="https://i.loli.net/2020/04/11/vwTshdjVL8GxbR2.png">
<meta property="og:image" content="https://i.loli.net/2020/04/12/Xy2o5njCTNmrRLi.png">
<meta property="og:image" content="https://i.loli.net/2020/04/12/RsBWlNigcMGXmCV.png">
<meta property="og:image" content="https://i.loli.net/2020/04/12/6LclPyOuVZ7fs2Y.png">
<meta property="og:image" content="https://i.loli.net/2020/04/12/f4Z2KiEk7GA39bB.png">
<meta property="og:image" content="https://i.loli.net/2020/04/12/kMj2eBg5Wmwt1LG.png">
<meta property="og:image" content="https://i.loli.net/2020/04/12/ygOFzE97AadnGpT.png">
<meta property="og:image" content="https://i.loli.net/2020/04/12/duc4WP7UifrAbOy.png">
<meta property="article:published_time" content="2020-04-09T11:47:07.000Z">
<meta property="article:modified_time" content="2020-04-12T12:04:51.060Z">
<meta property="article:author" content="LiyunZhang">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Computer Vision">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2020/04/10/8uBvQ1gKk7wndIC.png">

<link rel="canonical" href="http://http//www.laughingtree.cn/2020/04/09/07-CNN-Architectures/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>07. CNN Architectures | LaughingTree</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">LaughingTree</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags<span class="badge">16</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories<span class="badge">25</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="Searching..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2020/04/09/07-CNN-Architectures/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          07. CNN Architectures
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-09 19:47:07" itemprop="dateCreated datePublished" datetime="2020-04-09T19:47:07+08:00">2020-04-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-12 20:04:51" itemprop="dateModified" datetime="2020-04-12T20:04:51+08:00">2020-04-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Science/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Science</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Science/Computer-Vision-Stanford-CS231n/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Vision (Stanford CS231n)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="General"><a href="#General" class="headerlink" title="General"></a>General</h1><ol>
<li>When we say how many layers a network has, we mean how many layers in that network has weight. Namely, the sum of fully-connected layers and convolution layers. </li>
<li>The rule of naming a layer: <br />&emsp;If it is a fully-connected layer, its name will begin with “FC”. Behind “FC” is a number that stands for the number of neurons in this layer. Namely, the dimension of the output vector. <br />&emsp;If it is a convolution layer, its name begins with the size of the filter. In the middle is “conv”. At the end is the number of filters. <br />&emsp;Pooling layers write “Pool”. </li>
</ol>
<h1 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h1><ol>
<li>Published at 2012, AlexNet has many features: <br />&emsp;It is the first network using ReLU. <br />&emsp;It uses norm layers (not common now). <br />&emsp;It has heavy data augmentation. <br />&emsp;It uses the dropout with the probability of $0.5$. <br />&emsp;Its batch size is $128$, SGD momentum is $0.9$. <br />&emsp;The learning rate is $1e-2$, reduced by $10$ manually when validation accuracy plateaus. <br />&emsp;$L2$ weight decay is $5e-4$. <br />&emsp;$7$ models ensemble to create about $3%$ better accuracy. </li>
<li>Architecture: <br /><img src="https://i.loli.net/2020/04/10/8uBvQ1gKk7wndIC.png" width="10%"></li>
<li>AlexNet was trained on <script type="math/tex">GTX\ 580</script> GPU with only $3$ GB of memory. However, the output of its first convolution layer is $55\times55\times96$. So the network has to spread across $2$ GPUs, half the neurons (feature maps) on each GPU. </li>
<li>$CONV1$, $CONV2$, $CONV4$, $CONV5$ in AlexNet only have connections with feature maps on the same GPU. $CONV3$, $FC6$, $FC7$, $FC8$ have connections with all feature maps in the preceding layer; They communicate across GPUs. </li>
<li>ZFNect is AlexNet, except that $CONV1$ changed to $7\times7$ with stride $2$, and $CONV3, 4, 5$ uses $512, 1024, 512$ filters. </li>
</ol>
<h1 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h1><ol>
<li>The main feature of VGG is small filters and deeper networks. </li>
<li>VGG has many architectures with $16\sim19$ layers. The structure of VGG can be divided into blocks. So in VGG, we can name the convolution layers like $conv-x-y$, where $x$ is the number of blocks and $y$ is its position in that block. </li>
<li>All three fully-connected layers of VGG are in the last as AlexNet. </li>
<li>VGG only uses small filters of $3\times3,CONV$ stride $1$, pad $1$, and <script type="math/tex">2\times2,MAX\ POOL</script> stride $2$. Stack of three $3\times3 conv$ (stride $1$) layers has the same effective receptive field as one $7\times7 conv$ layer. However, a stack of three $3\times3$ convolution layer is deeper, more nonlinearities and fewer parameters than one $7\times7$ layer and <br />The size of the receptive field is the size of pixels that affect one pixel of the last layer. In this case, $3\times3$ pixels affect one pixel of the first convolution layer. Since the stride is $1$, we pad the receptive field of last layer with $1$, which makes the receptive field of the second convolution layer $5\times5$. Finally, the receptive field of the last layer is $7\times7$. </li>
<li>Most memory is spent on early convolution layers while most parameters are in late fully-connected layers. </li>
</ol>
<h1 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h1><ol>
<li>GoogLeNet replaced fully-connected layer with average pooling layer. Nevertheless, in order to finetune hyperparameters, it still added one fully-connected layer at the end. </li>
<li>GoogLeNet first used the inception module. The naive version of inception module is as followed. <br /><img src="https://i.loli.net/2020/04/11/whfvrYcQHAlX9Gj.png" width="30%"><br />It applied parallel filter operations on the input from the previous layer. With padding to make the output of four layers in the same size, the output of this inception module merely stacks them up. <br />However, its computational complexity is too high, not to mention that the pooling layer preserves feature depth, which means total depth after concatenation can only grow at every layer. </li>
<li>Hence, we use the bottleneck to reduce feature depth as followed. <br /><img src="https://i.loli.net/2020/04/11/vwTshdjVL8GxbR2.png" width="30%"><br />It uses less $1\times1$ filters then the depth of the input to reduce the complexity of calculation. </li>
<li>GoogLeNet stacks inception modules with dimension reduce on top of each other. <br /><img src="https://i.loli.net/2020/04/12/Xy2o5njCTNmrRLi.png" width='30%'><br />At the beginning is the stem network and at the end is the classifier output. <br />Nevertheless, it added some auxiliary classification outputs to inject additional gradient at lower layers. </li>
</ol>
<h1 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h1><ol>
<li>ResNet is so deep that it has $152$ layers. </li>
<li>The problem is that when continue stacking deeper layers on a “plain” convolutional neural network, the performance will become even worse. </li>
<li>The team assumed that the problem is an <em>optimization</em> problem; deeper models are harder to optimize. </li>
<li>Their solution is to use network layers to fit a residual mapping instead of directly trying to fit a desired underlying mapping. Namely, learn a function $H(x)$ to be the output to the next layer. <br /><img src="https://i.loli.net/2020/04/12/RsBWlNigcMGXmCV.png" width="10%"></li>
<li>They also assumed that learning a $H(x) = F(x)+x$ is much easier than learning a completely unknown $H(x)$. <br /><img src="https://i.loli.net/2020/04/12/6LclPyOuVZ7fs2Y.png" width="20%"></li>
<li>ResNet stacks residual blocks together, and every residual block has two $3\times3$ convolutional layers. <br />It also periodically double the number of filters and downsample spatially using stride $2$. <br />The ResNet begins with an additional convolutional layer and ends with a fully-connected layer. <br /></li>
<li>For deeper networks, they also use the bottleneck layer to improve efficiency as GoogLeNet. </li>
<li>To train a ResNet in practice: <br />&emsp;Add a BN layer after each convolutional layer. <br />&emsp;Use $Xavier/2$ initialization. <br />&emsp;Some hyperparameters: <br />&emsp;&emsp;Momentum: $0.9$<br />&emsp;&emsp;Learning rate: $0.1$, divided by $10$ when validation error plateaus. <br />&emsp;&emsp;Mini-batch size: 256<br />&emsp;&emsp;Weight decay: $1e-5$<br />&emsp;No dropout used. </li>
</ol>
<h1 id="Complexity"><a href="#Complexity" class="headerlink" title="Complexity"></a>Complexity</h1><ol>
<li>AlexNet: small compute, still memory heavy, lower accuracy</li>
<li>VGG: highest memory, most operations</li>
<li>GoogLeNet: most efficient</li>
<li>ResNet: Moderate efficiency depending on model, highest accuracy</li>
<li>ResNet, with inception, has the highest accuracy. </li>
</ol>
<h1 id="Other-Architectures"><a href="#Other-Architectures" class="headerlink" title="Other Architectures"></a>Other Architectures</h1><ol>
<li>NiN (Network in Network): <br />&emsp;Multiple convolutional layers with “micro-network” within each convolutional layer to compute more abstract features for local patches. <br />&emsp;The micro-network uses multilayer perceptron, like fully-connected layer. <br />&emsp;This is the precursor to GoogLeNet and ResNet bottleneck layers. </li>
<li>Identity Mappings in Deep Residual Networks: Creates a more direct path for propagating information throughout the network (moves activation to residual mapping pathway)</li>
<li>Wide residual network: <br />&emsp;Residuals are the critical factor, not depth. <br />&emsp;Use wider residual blocks ($F\times k$ filters instead of $F$ filters in each layer)<br />&emsp;$50$-layer wide ResNet outperforms $152$-layer original ResNet. <br />&emsp;Increasing width instead of depth is more computationally efficient. The computation can be easily parallelized. </li>
<li>ResNeXt: increase the width of theresidual block through multiple parallel pathways. <br /><img src="https://i.loli.net/2020/04/12/f4Z2KiEk7GA39bB.png" width="30%"></li>
<li>Stochastic depth: <br />&emsp;Motivation: reduce vanishing gradients and training time through short networks during training. <br />&emsp;Randomly drop a subset of layers during each training pass. <br />&emsp;Bypass with identity function. <br />&emsp;Use the full network at test time. </li>
<li>FractalNet: <br />&emsp;The key is transitioning efficiently from shallow to deep and residual representation is not necessary. <br />&emsp;It has both shallow and deep paths to output. <br />&emsp;It is trained with dropout, and test with full network. <br />&emsp;<img src="https://i.loli.net/2020/04/12/kMj2eBg5Wmwt1LG.png" width="50%"></li>
<li>Densely Connected Convolutional Networks: <br />&emsp;In dense block, each layer is connected to every other layer in a feedforward fashion. <br />&emsp;<img src="https://i.loli.net/2020/04/12/ygOFzE97AadnGpT.png" width="30%"><br />&emsp;It alleviates vanishing gradients, strengths feature propagation, encourages feature reuse. <br />&emsp;<img src="https://i.loli.net/2020/04/12/duc4WP7UifrAbOy.png" width="15%"></li>
<li>SqueezeNet: <br />&emsp;It has AlexNet-level accuracy with $50$ times fewer parameters and less than $0.5$ Mb model size. <br />&emsp;Fire modules consisting of a ‘squeeze’ layer with $1\times1$ filters feeding an ‘expand’ layer with $1\times1$ and $3\times3$ filters. </li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/Machine-Learning/" rel="tag"><i class="fa fa-tag"></i> Machine Learning</a>
              <a href="/tags/Deep-Learning/" rel="tag"><i class="fa fa-tag"></i> Deep Learning</a>
              <a href="/tags/Computer-Vision/" rel="tag"><i class="fa fa-tag"></i> Computer Vision</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/04/08/06-Deep-Learning-Software/" rel="prev" title="06. Deep Learning Software">
      <i class="fa fa-chevron-left"></i> 06. Deep Learning Software
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#General"><span class="nav-number">1.</span> <span class="nav-text">General</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#AlexNet"><span class="nav-number">2.</span> <span class="nav-text">AlexNet</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#VGG"><span class="nav-number">3.</span> <span class="nav-text">VGG</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#GoogLeNet"><span class="nav-number">4.</span> <span class="nav-text">GoogLeNet</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ResNet"><span class="nav-number">5.</span> <span class="nav-text">ResNet</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Complexity"><span class="nav-number">6.</span> <span class="nav-text">Complexity</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Other-Architectures"><span class="nav-number">7.</span> <span class="nav-text">Other Architectures</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="LiyunZhang"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">LiyunZhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">157</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liyun Zhang</span>
</div>
<div class="BbeiAn-info">
       浙ICP备 -
    <a target="_blank" href="http://www.miitbeian.gov.cn/" style="color:#000000"  rel="nofollow">19047088号-1</a> <!--a标签中增加nofollow属性，避免爬虫出站。-->|
    <a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=33011802001835" style="color:#000000;text-decoration:none;padding-left:30px;background:url(https://s1.ax1x.com/2018/09/29/ilmwIH.png) no-repeat left center" rel="nofollow">浙公网安备 33011802001835号</a>      <!--这里将图标作为了背景，以使得能和后面的文字在同一行-->

</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

</body>
</html>
