<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/avatar.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/avatar.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://http://www.laughingtree.cn').hostname,
    root: '/',
    scheme: 'Mist',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":true},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta property="og:type" content="website">
<meta property="og:title" content="LaughingTree">
<meta property="og:url" content="http://http//www.laughingtree.cn/page/2/index.html">
<meta property="og:site_name" content="LaughingTree">
<meta property="article:author" content="LiyunZhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://http//www.laughingtree.cn/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>LaughingTree</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">LaughingTree</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags<span class="badge">20</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories<span class="badge">28</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="Searching..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2020/04/05/04-Convolutional-Neural-Networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/05/04-Convolutional-Neural-Networks/" class="post-title-link" itemprop="url">04. Convolutional Neural Networks</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-04-05 09:29:06 / Modified: 16:33:23" itemprop="dateCreated datePublished" datetime="2020-04-05T09:29:06+08:00">2020-04-05</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Science/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Science</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Science/Computer-Vision-Stanford-CS231n/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Vision (Stanford CS231n)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Convolution-Layer"><a href="#Convolution-Layer" class="headerlink" title="Convolution Layer"></a>Convolution Layer</h1><ol>
<li>Fully-connected layer extracts pixels of an image into a one-dimensional vector. However, the convolution layer tends to preserve the spatial structure of that image. </li>
<li>In the convolution layer, we convolve a smaller filter with the image; namely, we slide it over the image spatially, computing dot products. </li>
<li>The size of the matrix of an image is usually $N\times N\times z$. The filter we choose can have random $F$, but the $z$ must be maintained. So the filter can be anything in the form of $F\times F\times z$. </li>
<li>Every filter is a weighted matrix. We use it to cover up some location of the image, then calculate the sum of the products of the corresponding numbers. <br />This process is the same as we stretch the filter and the covered area into two one-dimensional vectors and calculate the dot product of these two vectors. </li>
<li>After each dot product, we get a number $w^Tx+b$ instead of a vector. So each filter can produce an $F’\times F’\times1$ activation map. Furthermore, we can use multiple filters to create multiple activation maps. With $k$ filters, the activation matrix will be $F’\times F’\times k$. </li>
<li>The earlier convolution layers will learn lower-level features while the later ones will learn higher-level features. </li>
<li>One thing that will affect the size of the activation map is the stride we choose when the filter is slid around the image. If the stride is $S$, the size will be $\displaystyle(\frac{N-F}{S}+1)\times(\frac{N-F}{S}+1)\times n$. <br />Stride can be any integer as long as $N-F$ is dividable by it. </li>
<li>Another common phenomenon is padding. When we say “zero pad with $P$”, we mean that add $a$ laps zero bounds around the original matrix. <br />So the actual size of a matrix which pad with $P$ we need to slide is $(N+2P)\times (N+2P)\times z$. <br />The padding is used to maintain the input size. So in convolution layer, we often pad the image with $\displaystyle\frac{F-1}{2}$ laps of zero pixel border. Nevertheless, the pad is not necessary; sometimes we do not use padding; sometimes we pad less, sometimes we pad more. </li>
</ol>
<h1 id="Other-layers"><a href="#Other-layers" class="headerlink" title="Other layers"></a>Other layers</h1><ol>
<li>Pooling layer makes the representations smaller and more manageable. It operates over each activation map independently and downsamples them. </li>
<li>The pooling layer also has a filter, but instead of doing a dot product, it may take the maximum of the numbers (Max Pooling Layer). </li>
<li>In convention, we do not want any overlap in pooling layer, unlike in the convolution layer. </li>
<li>Typically, the last layer of a convolution neural network will be a fully-connected layer, which connects the class labels to the input. </li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2020/04/04/03-Backpropagation-and-Neural-Networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/04/03-Backpropagation-and-Neural-Networks/" class="post-title-link" itemprop="url">03. Backpropagation and Neural Networks</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-04 19:16:49" itemprop="dateCreated datePublished" datetime="2020-04-04T19:16:49+08:00">2020-04-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-07 13:28:53" itemprop="dateModified" datetime="2020-05-07T13:28:53+08:00">2020-05-07</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Science/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Science</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Science/Computer-Vision-Stanford-CS231n/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Vision (Stanford CS231n)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h1><ol>
<li>Backpropagation is used for calculating the gradient. </li>
<li>In each gradient, we need to calculate the derivative of $f$ with respect to each component. </li>
<li>Any function $f$ can be decomposed into a computational graph, which contains several nodes. Each node represents one single simple calculation with some inputs and one output. </li>
<li>We can easily calculate the local gradient for each node function $q$, $\displaystyle\frac{\partial q}{\partial x_i}$. </li>
<li>With the chain rule, we can multiply each local gradient to get $\displaystyle\frac{\partial f}{\partial x_i}$. </li>
<li>In programming, we usually start from the end of the computational graph, namely $f=f$. Its local gradient is $\displaystyle\frac{\partial f}{\partial f}=1$. <br />Then we calculate backwardly the last but one node. <br />Each node except the last one multiplies the previously calculated gradient to get the global gradient. <br />The global gradients of the leaf nodes are the gradient we want. <br /><img src="/img/03.BackpropagationandNeuralNetworks01.png" width="40%">$\displaystyle\frac{\partial f}{\partial q},\frac{\partial q}{\partial W},\frac{\partial q}{\partial X},\frac{\partial f}{\partial b}$ are all local gradients, while $\displaystyle1.0,\frac{\partial f}{\partial q}\times1.0,\frac{\partial q}{\partial W}\frac{\partial f}{\partial q},\frac{\partial q}{\partial X}\frac{\partial f}{\partial q},\frac{\partial f}{\partial b}\times1.0$ are all global gradients. </li>
<li>We can also group some nodes to form a complicated node as long as we can write down the local gradient. </li>
<li>Add gate distributes the global gradient of the output as the global gradient of each input. <br />Max gate gives the output local gradient to the larger input as its global gradient and gives $0$ to another input. <br />Multiplication gate switches the values of inputs as their local gradient. </li>
<li>If inputs are vectors, the local gradients are the Jacobian matrices; namely, we need to calculate each element of the output with respect to each element of the input. Given the property of partial derivative, the Jacobian matrices are diagonal. </li>
<li>Always check: The gradient with respect to a variable should have the same shape as the variable. </li>
<li>In implement, we can make each gate a class with a forward function and a backward function. The forward function takes in the inputs and returns the forward calculation output. The backward function takes in the previous gradient and returns the gradients with respect to each component. </li>
</ol>
<h1 id="Neural-Network"><a href="#Neural-Network" class="headerlink" title="Neural Network"></a>Neural Network</h1><ol>
<li>Instead of using a single linear score function, we use multiple linear functions in neural networks with nonlinear functions in between. </li>
<li>The nonlinear functions are called the activation function. </li>
<li>There are many kinds of activation functions: <br />&emsp;Sigmoid: $\sigma(x)=\displaystyle\frac{1}{1+e^{-x}}$<br />&emsp;tanh: $tanh(x)$<br />&emsp;ReLu: $max(0,x)$<br />&emsp;Leaky ReLu: $max(0.1x,x)$<br />&emsp;Maxout: $max(w_1^Tx+b_1,w^T_2x+b_2)$<br />&emsp;ELU: $\left\{\begin{array}{}x&amp;x≥0\\\alpha(e^x-1)&amp;x&lt;0 \end{array}\right.$</li>
<li>The layers which take in the output of the previous layer and do one linear calculation and one nonlinear calculation is called fully-connected layers. </li>
<li>The first layer is the input layer, which takes in the input and calculate. So it is a fully-connected layer. <br />The last layer is the output layer, which does no calculation, simply outputs the result. So it is not a fully-connected layer. <br />All layers except these two layers are hidden layers. </li>
<li>What we called “$2$-layer Neural Network” is “$2$-fully-connected-layer Neural Network” or “$1$-hidden-layer Neural Network”. </li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2020/04/04/02-Loss-Functions-and-Optimization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/04/02-Loss-Functions-and-Optimization/" class="post-title-link" itemprop="url">02. Loss Functions and Optimization</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-04-04 15:30:24 / Modified: 19:15:51" itemprop="dateCreated datePublished" datetime="2020-04-04T15:30:24+08:00">2020-04-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Science/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Science</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Science/Computer-Vision-Stanford-CS231n/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Vision (Stanford CS231n)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h1><p>A loss function tells how good our current classifier is. </p>
<h2 id="Data-Loss"><a href="#Data-Loss" class="headerlink" title="Data Loss"></a>Data Loss</h2><ol>
<li>Given a dataset of examples $\{(x_i,y_i)\}^N_{i=1}$ where $x_i$ is an image and $y_i$ is an integer label. Loss over the dataset is a sum of loss over examples: $L=\displaystyle\frac{1}{N}\sum_iL_i(f(x_i,W),y_i)$. </li>
<li>There are infinitely many $W$ to make $L=0$. </li>
</ol>
<h3 id="SVM-Classifier"><a href="#SVM-Classifier" class="headerlink" title="SVM Classifier"></a>SVM Classifier</h3><ol>
<li>Multiclass SVM loss (Hinge loss): $L_i=\displaystyle\sum_{j≠y_i}max(0,s_j-s_{y_i}+1)$. $s_i$ is the score of the $i$th class. </li>
<li>The minimum loss of SVM is $0$ when all prediction is correct. The maximum loss is infinity when the prediction is as wrong as possible. </li>
<li>If at initialization $W$ is small, so all $s\approx 0$, the loss will be <script type="math/tex">the\ number\ of\ class-1</script>. </li>
</ol>
<h3 id="Softmax-Classifier-Multinomial-Logistic-Regression"><a href="#Softmax-Classifier-Multinomial-Logistic-Regression" class="headerlink" title="Softmax Classifier (Multinomial Logistic Regression)"></a>Softmax Classifier (Multinomial Logistic Regression)</h3><ol>
<li>We can use the scores to calculate the probabilities of all labels given the condition of the image is $x_i$. </li>
<li>We exponentiate scores to make every term positive. So the probability of the actual label being $k$ is $P(Y=k|X=x_i)=\displaystyle\frac{e^{s_k}}{\sum_je^{s_j}}$, which is called the softmax function. </li>
<li>To maximize the log-likelihood, or to minimize the negative log-likelihood of the correct class. <script type="math/tex">L_i=-log\ P(Y=y_i|X=x_i)=-log\ \displaystyle\frac{e^{s_{y_i}}}{\sum_je^{s_j}}</script>. </li>
<li>The goal is to maximize the probability of the right label. It is easier to maximize the log function than the raw probability. Also, the loss function is describing how bad the model is, so we take the negative of it. </li>
<li>Three steps for softmax classifier: exponentiate the scores; normalize them; take the negative log of the correct label. </li>
<li>The minimum possible loss is $0$ when the model is totally right (the probability of the accurate label is $1$). The maximum is infinity when the model is entirely wrong (the probability of the correct label is $0$). However, these two situations will occur. </li>
<li>A slight change in a datapoint might when changing the loss of SVM if the label is right, but it will change the loss of softmax in any situation. </li>
</ol>
<h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><ol>
<li>The only thing we care about is the performance on the test set. So we need to tell our algorithm more than the performance on the training data. </li>
<li>To avoid overfitting the training data, we should add regularization to the loss, which will punish when the model is complicated. So the loss becomes $L=\displaystyle\frac{1}{N}\sum_iL_i(f(x_i,W),y_i)+\lambda R(W)$. $\lambda$ is a hyperparameter called regularization strength. </li>
<li>$L2$ regularization: $R(W)=\displaystyle\sum_k\sum_lW_{k,l}^2$<br />$L1$ regularization: $R(W)=\displaystyle\sum_k\sum_l|W_{k,l}|$<br />Elastic net $(L1+L2)$: $R(W)=\displaystyle\sum_k\sum_l\beta W_{k,l}^2+|W_{k,l}|$</li>
<li>The idea of regularization is to penalize the complexity of model rather than trying to fit the training data. </li>
<li>$L2$ regularization also corresponds MAP inference using a Gaussian prior on $W$. </li>
<li>The regularization function is a problem-dependent hyperparameter. </li>
<li>If at initialization $W$ is small so all $s\approx 0$, the loss will be <script type="math/tex">-log\ c</script>. $c$ is the number of classes. </li>
</ol>
<h1 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h1><ol>
<li>The strategy here is to follow the gradient of $f$. The opposite direction of the gradient is the greatest decrease in the function. </li>
<li>The numerical way to calculate the gradient to increase one component of $W$ a little bit, then use the formula $\displaystyle\frac{df}{dx}=\frac{f(x+h)-f(x)}{h}$ to get the corresponding component in the gradient. </li>
<li>The faster way to get the gradient is the analytic way. In practice, always use the analytic gradient, but check implementation with numerical gradient. This is called a gradient check. </li>
<li>Gradient descent: first calculate the gradient, then subtract the multiplication of learning rate and the gradient from the weight. </li>
<li>Calculation of the gradient can be slow, so in practice, we usually use the stochastic gradient descent, which only calculates the gradient of part of the training set. </li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2020/04/04/01-Image-Classification/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/04/01-Image-Classification/" class="post-title-link" itemprop="url">01. Image Classification</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-04-04 12:11:23 / Modified: 16:35:39" itemprop="dateCreated datePublished" datetime="2020-04-04T12:11:23+08:00">2020-04-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Science/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Science</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Science/Computer-Vision-Stanford-CS231n/" itemprop="url" rel="index">
                    <span itemprop="name">Computer Vision (Stanford CS231n)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="General"><a href="#General" class="headerlink" title="General"></a>General</h1><ol>
<li>The conventional way to solve image classification problem: <br />Data-driven Approach: <br />&emsp;Collect a dataset of images and labels<br />&emsp;Use Machine Learning to train a classifier<br />&emsp;Evaluate the classifier on new images</li>
<li>The API has two main functions: <br />&emsp;”Train” function: input images and labels then output a model. <br />&emsp;”Predict” function: input model and images then output predictions. </li>
</ol>
<h1 id="Nearest-Neighbor"><a href="#Nearest-Neighbor" class="headerlink" title="Nearest Neighbor"></a>Nearest Neighbor</h1><h2 id="Train-and-Predict"><a href="#Train-and-Predict" class="headerlink" title="Train and Predict"></a>Train and Predict</h2><ol>
<li>In the training function, we memorize all data and labels. </li>
<li>In the prediction function, we predict the label of the most similar training image. </li>
<li>More specific, in prediction, we find the closest image and predict the label of the nearest image. </li>
<li>With $N$ example, the complexity of training is $O(1)$ and prediction is $O(N)$. This is bad because we want classifiers that are fast at prediction even if the training is slow</li>
<li>Another problem with this algorithm is the curse of dimensionality. As the data enter the higher dimension, they become sparse. So we need a lot more datas to make space dense, which is possibly out of control. </li>
</ol>
<h2 id="Compare-Images"><a href="#Compare-Images" class="headerlink" title="Compare Images"></a>Compare Images</h2><ol>
<li>In order to select the most similar image, we need to compare each image. So it is necessary to choose a compare function. </li>
<li>The first choice is the <code>L1 distance</code> or <code>Manhattan distance</code>. $d_1(I_1,I_2)=\displaystyle\sum_p|I_1^p-I_2^p|$. </li>
<li>Another choice is the <code>L2 distance</code> or <code>Euclidean distance</code>. $d_2(I_1,I_2)=\sqrt{\sum_p(I_1^p-I_2^p)^2}$. </li>
<li>The difference between the two choices is that $L1$ distance is coordinate-dependent wile $L2$ distance is coordinate-independent. If we rotate the coordinate frame, $L1$ distance will be changed while $L2$ distance remains the same. </li>
<li>Actually, distance matrices on pixels are not informative. </li>
</ol>
<h2 id="K-Nearest-Neighbors"><a href="#K-Nearest-Neighbors" class="headerlink" title="K-Nearest Neighbors"></a>K-Nearest Neighbors</h2><ol>
<li>The algorithm above determines the result with only one data. Therefore it is easily affected by noise. </li>
<li>To reduce the affection of noise, we use the more “democratic” way. We take majority vote from $K$-nearest neighbours. </li>
<li>The algorithm mentioned earlier is a $K=1$ algorithm. </li>
<li>We often take $K$ some odd number instead of an even number. </li>
<li>When $K$ is smaller than the number of classes of labels, some image may be unpredictable if the vote of all $K$-nearest neighbours is a tie. So we will make a random guess among the majority winners. </li>
</ol>
<h1 id="Hyperparameter"><a href="#Hyperparameter" class="headerlink" title="Hyperparameter"></a>Hyperparameter</h1><ol>
<li>Hyperparameter is choices about the algorithm that we set rather than learn. As the number of $K$ above, which distance we are using, they are both hyperparameters. </li>
<li>Hyperparameter is very problem-dependent. We must try them all out and see what works best. </li>
</ol>
<h2 id="Setting-Hyperparameters"><a href="#Setting-Hyperparameters" class="headerlink" title="Setting Hyperparameters"></a>Setting Hyperparameters</h2><ol>
<li>Mark that when setting hyperparameters, we never touch a finger on the test set. The test must be unseen from model and us. </li>
<li>So we must split data into a training set, a validation set and a test set. Choose hyperparameters on the validation set and evaluate on the test set. </li>
<li>Furthermore, we can use the cross-validation by splitting data into folds. Try each fold as validation and average the results. This is useful but takes much time. So we mostly use it on small datasets and seldom use it on large datasets. </li>
<li>In order to avoid bias on each dataset, we usually split data randomly. </li>
</ol>
<h1 id="Linear-Classification"><a href="#Linear-Classification" class="headerlink" title="Linear Classification"></a>Linear Classification</h1><ol>
<li>The parametric approach takes in the image as a vertical vector $\vec{x}$, and a parameter matrix (weight matrix) $W$ then outputs scores of each class. <br />For $\vec{x}$, we take the numbers in each image out in order and put them into a vertical vector. </li>
<li>In linear classification, $f(\vec{x},W)=W\vec{x}$. Sometimes, we might want to add a bias vector $\vec{b}$, which makes the function $f(\vec{x}, W)=W\vec{x}+\vec{b}$. </li>
<li>Each row of $W$ is a template of how each pixel in the image will affect each class. </li>
<li>The linear classification model splits the space into pieces with linear decision boundaries. Each class takes one piece. </li>
<li>We predict the label as the label of the highest class score. </li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2020/03/22/15-Classical-Statistical-Inference/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/22/15-Classical-Statistical-Inference/" class="post-title-link" itemprop="url">15. Classical Statistical Inference</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-03-22 10:11:49" itemprop="dateCreated datePublished" datetime="2020-03-22T10:11:49+08:00">2020-03-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-02 16:52:07" itemprop="dateModified" datetime="2020-04-02T16:52:07+08:00">2020-04-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Mathematics/" itemprop="url" rel="index">
                    <span itemprop="name">Mathematics</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Mathematics/Probability-MIT-6-041/" itemprop="url" rel="index">
                    <span itemprop="name">Probability (MIT 6.041)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="General"><a href="#General" class="headerlink" title="General"></a>General</h1><ol>
<li>In classical statistics, we see the unknowns as constants instead of random variables in Bayesian statistics. </li>
<li>The distribution of $X$ depends on $\theta$. This is not a conditional distribution $p_{X|\Theta}$ or $f_{X|\Theta}$ in the Bayesian statistics but only a common distribution $p_X(x;\theta)$ or $f_X(x;\theta)$. </li>
<li>For vectors $X$ and $\theta$: $p_{X_1,…X_2}(x_1,…,x_n;\theta_1,…,\theta_m)$. </li>
<li>Problem types: <br />&emsp;Hypothesis testing: choose the correct model from several discrete model. Each model contains only one model. <br />&emsp;Composite hypotheses: some models might consist of more than one models. <br />&emsp;Estimation: design an estimator $\hat\Theta$ to keep estimation error $\hat\Theta-\theta$ small. </li>
</ol>
<h1 id="Maximum-Likelihood-Estimation"><a href="#Maximum-Likelihood-Estimation" class="headerlink" title="Maximum Likelihood Estimation"></a>Maximum Likelihood Estimation</h1><ol>
<li>Pick $\theta$ that makes data most likely. <script type="math/tex">\hat\theta_{ML}=arg\ max_\theta\ p_X(x;\theta)</script>. </li>
<li>In Bayesian MAP estimation, we actually only need to maximize <script type="math/tex">\hat\theta_{MAP}=arg\ max_\theta\ p_{X|\Theta}(x|\theta)p_\Theta(\theta)</script>. If $p_\Theta(\theta)$ is a constant, these two is going to maximize the same thing. </li>
<li>The estimate $\theta$ is the realized value of estimator $\hat\Theta$. </li>
<li>In many applications, the observations $X_i$ are assumed to be independent, in which case, the likelihood function is of the form $p_X(x_1,…,x_n;\theta)=\displaystyle\prod^n_{i=1}p_{X_i}(x_i;\theta)$. <br />In this case, it is often use the logarithm form, which is called log-likelihood function, to find the maximum. <script type="math/tex">log\ p_X(x_1,…,x_n;\theta)=log\displaystyle\prod^n_{i=1}p_{X_i}(x_i;\theta)=\sum^n_{i=1}log\ p_{X_i}(x_i;\theta)</script></li>
</ol>
<h2 id="Desired-Properties-of-Estimators"><a href="#Desired-Properties-of-Estimators" class="headerlink" title="Desired Properties of Estimators"></a>Desired Properties of Estimators</h2><ol>
<li>Unbiased: $E_\theta[\hat\Theta]=\displaystyle\int f_{\hat\Theta}(\hat\theta;\theta)\hat\theta d\hat\theta =\theta$. $\theta$ is the true value. </li>
<li>Consistent: $\hat\Theta_n\to\theta$. </li>
<li>Small mean squared error: $E_\theta[(\hat\Theta-\theta)^2]=var_\theta(\hat\Theta-\theta)+(E_\theta[\hat\Theta-\theta])^2=var_\theta(\hat\Theta)+(bias_\theta)^2$</li>
</ol>
<h1 id="Confidence-Interval"><a href="#Confidence-Interval" class="headerlink" title="Confidence Interval"></a>Confidence Interval</h1><ol>
<li>An estimate $\hat\Theta_n$ may not be informative enough. </li>
<li>An $(1-\alpha)$ confidence interval is a random interval $[\Theta_n^-,\Theta_n^+]$, such that $P(\Theta^-_n≤\theta≤\Theta^+_n)≥1-\alpha,\forall\alpha$. </li>
<li>We usually use the normal table to calculate the confidence interval of sample mean. <br />&emsp;According to the central limit theorem, $P\left(\displaystyle\frac{|\hat\Theta_n-\theta|}{\displaystyle\frac{\sigma}{\sqrt{n}}}≤z \right)\approx\Phi(z)$. <br />&emsp;So $P\left(\hat\Theta_n-\displaystyle\frac{z\sigma}{\sqrt{n}}≤\theta≤\hat\Theta_n+\frac{z\sigma}{\sqrt{n}} \right)\approx1-\alpha$<br />&emsp;$\Phi(z)=1-\displaystyle\frac{\alpha}{2}$. </li>
<li>If we don’t know about $\sigma$. <br />&emsp;Option $1$: use the upper bound on $\sigma$. <br />&emsp;Option $2$: use ad hoc estimate of $\sigma$. <br />&emsp;Option $3$: use the generic estimate of variance<br />&emsp;&emsp;$\sigma^2=E[(X_i-\theta)^2]$, so $\hat\sigma^2=\displaystyle\frac{1}{n}\sum^n_{i=1}(X_i-\theta)^2$. But $\theta$ is still unknown, so we use the estimator instead. <br />&emsp;&emsp;$\hat{S}_n^2=\displaystyle\frac{1}{n-1}\sum^n_{i=1}(X_i-\hat\Theta_n)^2$. And $E[\hat{S}^2_n]=\hat\sigma^2\to\sigma^2$. </li>
</ol>
<h1 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h1><ol>
<li>Model: $y\approx\theta_0+\theta_1x$ to minimize $\displaystyle\sum^n_{i=1}(y_i-\theta_0-\theta_1x_i)^2$. </li>
<li>Interpretation: $Y_i=\theta_0+\theta_1x_i+W_i$, $W_i\sim N(0,\sigma^2)$. </li>
<li>Likelihood function $f_{X,Y|\theta}(x,y;\theta)=c\cdot exp\{\displaystyle-\frac{1}{2\sigma^2}\sum^n_{i=1}(y_i-\theta_0-\theta_1x_i)^2\}$. So we need to maximize it. </li>
<li>Take the logs, maximize <script type="math/tex">-log\ c\cdot\displaystyle\frac{1}{2\sigma^2}\sum^n_{i=1}(y_i-\theta_0-\theta_1x_i)^2</script>. The same as minimize $\displaystyle\sum^n_{i=1}(y_i-\theta_0-\theta_1x_i)^2$. </li>
<li>The solution is $\hat\theta_1=\displaystyle\frac{\displaystyle\sum^n_{i=1}(x_i-\bar{x})(y_i-\bar{y})}{\displaystyle\sum^n_{i=1}(x_i-\bar{x})^2}$ and $\hat\theta_0=\bar{y}-\hat\theta_1\bar{x}$. </li>
<li>This form can be interpreted as estimates of $\hat\theta_1=\displaystyle\frac{cov(X,Y)}{var(X)}$ and $\hat\theta_0=E[Y]-\hat\theta_1E[X]$. </li>
<li>Multiple linear regression: <br />&emsp;Model: $y\approx\theta_0+\theta_1x_1+\theta_2x_2+…$. <br />&emsp;Formulation: <script type="math/tex">min_{\theta_0,\theta_1,…}\ \displaystyle\sum^n_{i=1}(y_i-\theta_0-\theta_1x_1-\theta_2x_2-…)^2</script>. </li>
<li>General method: set the derivative to zero. </li>
<li>We can also choose different variables $y\approx\theta_0+\theta_1h(x)$. Since $\theta_0$ and $\theta_1$ are the unknowns, this is still a linear function. </li>
<li>Some concerns: <br />&emsp;noise might affect the result<br />&emsp;multiple variables have different correlation<br />&emsp;the regression function only shows the prediction based on other variables, but says nothing about the causal relations. </li>
</ol>
<h1 id="Binary-Hypothesis-Testing"><a href="#Binary-Hypothesis-Testing" class="headerlink" title="Binary Hypothesis Testing"></a>Binary Hypothesis Testing</h1><ol>
<li>Null hypothesis $H_0$: $X\sim p_X(x;H_0)$ or $X\sim f_X(x;H_0)$<br />Alternative hypothesis $H_1$: $X\sim p_X(x;H_1)$ or $X\sim f_X(x;H_1)$. </li>
<li>Partition the space of possible data vectors Rejection region R: reject $H_0$ if and only if $x\in R$. </li>
<li>Types of errors: <br />&emsp;False rejection: $H_0$ is true but rejected: $\alpha(R)=P(X\in R;H_0)$. <br />&emsp;False acceptance: $H_0$ is false but accepted: $\beta(R)=P(X\notin R;H_1)$. <br />&emsp;$\alpha$ and $\beta$ have a trade off relation. When $\alpha$ increases, $\beta$ decreases and vice versa. </li>
<li>Likelihood ratio test of Bayesian test: choose $H_1$ if <br />$P(H_1|X=x)&gt;P(H_0|X=x)$ or $\displaystyle\frac{P(X=x|H_1)P(H_1)}{P(X=x)}&gt;\frac{P(X=x|H_0)P(H_0)}{P(X=x)}$ or $\displaystyle\frac{P(X=x|H_1)}{P(X=x|H_0)}&gt;\frac{P(H_0)}{P(H_1)}$. </li>
<li>Likelihood ratio test of Nonbayesian test: choose $H_1$ if <br />$L(x)=\displaystyle\frac{P(X=x;H_1)}{P(X=x;H_0)}&gt;\epsilon$ when $X$ is discrete and if $\displaystyle\frac{f_X(x;H_1)}{f_X(x;H_0)}&gt;\epsilon$ when $X$ is continuous. <br />Normally, we can concise the inequality to $\displaystyle\sum_if(X_i)&gt;\epsilon’$, which is called the statistic. <br />Then fix the false rejection probability $\alpha$, and choose $\epsilon$ so that <script type="math/tex">P(reject\ H_0;H0)=\alpha</script>, or $P\left(\displaystyle\sum_if(X_i)&gt;\epsilon’;H_0\right)=\alpha$. <br />Usually, we can solve the later equation with CLT when statistic is large. </li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2020/03/21/14-Bayesian-Statistical-Inference/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/21/14-Bayesian-Statistical-Inference/" class="post-title-link" itemprop="url">14. Bayesian Statistical Inference</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-03-21 16:38:18 / Modified: 23:39:20" itemprop="dateCreated datePublished" datetime="2020-03-21T16:38:18+08:00">2020-03-21</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Mathematics/" itemprop="url" rel="index">
                    <span itemprop="name">Mathematics</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Mathematics/Probability-MIT-6-041/" itemprop="url" rel="index">
                    <span itemprop="name">Probability (MIT 6.041)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Statistics"><a href="#Statistics" class="headerlink" title="Statistics"></a>Statistics</h1><ol>
<li>In probability, every unambiguous question has a unique correct answer. </li>
<li>But in statistics, for any particular problem, there may be several reasonable methods, yielding different answers. In general, there is no principled way for selecting the best method, unlees one makes several assumptions and imposes additional constraints on the inference problem. </li>
<li>We can narrow down the search for the right method by requiring certain desirable properties. </li>
<li>The choice of one method over another usually hinges on several factors: performance guarantees, past experience, common sense, as well as the consensus of the statistics community on the applicability of a particular method on a particular problem type. </li>
<li>Bayesian statistics treats unknown parameters as random variables with known prior distributions. </li>
<li>In parameter estimation, we want to generate estimates that are close to the true values of the parameters in some probabilistic sense. </li>
<li>In hypothesis testing, the unknown parameter takes one of a finite number of values, corresponding to competing hypotheses; we want to choose one of the hypotheses, aiming to achieve a small probability of error. </li>
</ol>
<h1 id="Bayesian-Inference-and-the-Posterior-Distribution"><a href="#Bayesian-Inference-and-the-Posterior-Distribution" class="headerlink" title="Bayesian Inference and the Posterior Distribution"></a>Bayesian Inference and the Posterior Distribution</h1><ol>
<li>In Bayesian inference, the unknown quantity of interest, which we denote by $\Theta$, is modeled as a random variable or as a finite collection of random variables. </li>
<li>We aim to extract information about $\Theta$, based on observing a collection $X=(X_1,…,X_n)$ of related random variables, called observations, measurements, or an observation vector. </li>
<li>In Bayesian Inference, we start with a prior distribution $p_\Theta$ or $f_\Theta$ for the unknown random variable $\Theta$. We have a model $p_{X|\Theta}$ or $f_{X|\Theta}$ of the observation vector $X$. After observing the value $x$ of $X$, we form the posterior distribution $p_{\Theta|X}$ or $f_{\Theta|X}$, using the appropriate version of Bayes’s rule. </li>
<li>Once a particular value $x$ of $X$ has been ovserved, a complete answer to the Bayesian inference problem is provided by the posterior distribution of $\Theta$. </li>
<li>The case of multiple unknown parameters is entirely similar. </li>
<li>After getting the posterior distribution, we are certainly to make some decision with it to minimize the probability of error. </li>
</ol>
<h1 id="Hypothesis-and-Estimate"><a href="#Hypothesis-and-Estimate" class="headerlink" title="Hypothesis and Estimate"></a>Hypothesis and Estimate</h1><ol>
<li>An estimator is a random variable of the form $\hat\Theta=g(X)$, for some function $g$. Different choices of $g$ correspond to different estimators. </li>
<li>An estimate is the value $\hat\theta$ of an estimator, as determined by the realized value $x$ of observation $X$. </li>
<li>In estimation problem, $\Theta$ is continuous. In hypothesis problem, $\Theta$ is descrete with small sample space. </li>
</ol>
<h2 id="MAP"><a href="#MAP" class="headerlink" title="MAP"></a>MAP</h2><ol>
<li>One way to make the decision is to use the Maximum a Posteriori probability (MAP) rule. <br />Given the value $x$ of the observation, we select a value of $\theta$, denoted $\hat\theta$, that maximizes the posterior distribution. Namely: <br /><script type="math/tex">\hat\theta=\left\{\begin{array}{}arg\ max_\theta\ p_{\Theta|X}(\theta|x)&\Theta\ discrete\\arg\ max_\theta\ f_{\Theta|X}(\theta|x)&\Theta\ continuous \end{array}\right.</script></li>
<li>The denominator of the posterior distribution $p_X$ or $f_X$ which is $\Theta$ independent. Thus, to maximize the posterior, we only need to choose a value of $\theta$ that maximizes the numerator. </li>
<li>If $\Theta$ takes only a finite number of values, the MAP rule minimizes (over all decision rules) the probability of selecting an incorrect hypothesis. This is true for both the unconditional probability of error and the conditional one, given any observation value $x$. </li>
<li>In the absence of additional assumptions, a point estimate carries no guarantees on its accuracy. Thus, it’s usually desirable to also report some additional information, such as the conditional mean squared error. </li>
</ol>
<h2 id="LMS"><a href="#LMS" class="headerlink" title="LMS"></a>LMS</h2><ol>
<li>This rule tries to minimize $E[(\Theta-c)^2]$, where $c$ is the estimate. <br />Expand this to get $E[\Theta^2]-2cE[\Theta]+c^2$. The minimum is achieved at $c=E[\Theta]$. </li>
<li>So the optimal estimate is $E[\Theta]$. And the error is $E[(\Theta-E[\Theta])^2]=var(\Theta)$. </li>
<li>The conditional case is the same. Minimize $E[(\Theta-c)^2|X=x]$ is minimized by $c=[\Theta|X=x]$. </li>
<li>$E[\Theta|X]$ minimizes $E[(\Theta-g(X))^2]$ over all estimators $g(\cdot)$. </li>
<li>If we have multiple observations, $\hat\theta=E[\Theta|X_1,…,X_n]$, $E[(\Theta-E[\Theta|X_1,…,X_n])^2]≤E[(\Theta-g(X_1,…,X_n))^2]$ for all estimators $g(X_1,…,X_n)$. </li>
<li>If we have multiple parameters, we need to minimize $E[(\Theta_1-\hat\Theta_1)^2]+…+E[(\Theta_m-\hat\Theta_m)^2]$. The result is $\hat\Theta_i=E[\Theta_i|X_1,…,X_n]$. </li>
</ol>
<h3 id="Estimation-Error"><a href="#Estimation-Error" class="headerlink" title="Estimation Error"></a>Estimation Error</h3><ol>
<li>Let $\hat\Theta=E[\Theta|X]$ be the LMS estimator and $\tilde\Theta=\hat\Theta-\Theta$ be the associated estimation error. </li>
<li>The estimation error $\tilde\Theta$ is unbiased, i.e. it has zero unconditional and conditional mean $E[\tilde\Theta]=0$ and $E[\tilde\Theta|X=x]=0$ for all $x$. </li>
<li>The estimation error $\tilde\Theta$ is uncorrelated with the estimate $\hat\Theta$: $cov(\hat\Theta, \tilde\Theta)=0$. </li>
<li>The variance of $\Theta$ can be decomposed as $var(\Theta)=var(\hat\Theta)+var(\tilde\Theta)$. </li>
</ol>
<h3 id="Linear-LMS"><a href="#Linear-LMS" class="headerlink" title="Linear LMS"></a>Linear LMS</h3><ol>
<li>The calculation for multiple observations and multiple parameters might be hard. So we might choose another way to estimate. </li>
<li>A linear estimator of a random variable $\Theta$, based on observations $X_1,…,X_n$ has form $\hat\Theta=a_1X_1+…+a_nX_n+b$. </li>
<li>Given a particular choice of the scalars $a_1,…,a_n,b$, the corresponding mean squared error is $E[(\Theta-a_1X_1-…-a_nX_n-b)^2]$. </li>
</ol>
<h4 id="Single-Observation"><a href="#Single-Observation" class="headerlink" title="Single Observation"></a>Single Observation</h4><ol>
<li>Suppose that $a$ has already been chosen. This is the same as choosing a constant $b$ to estimate the random variable $\Theta-aX$. The best choice is $b=E[\Theta-aX]=E[\Theta]-aE[X]$. </li>
<li>Now we only need to minimize $E[(\Theta-aX-E[\Theta]+aE[X])^2]$. </li>
<li>Rewrite this expression as $var(\Theta-aX)=\sigma_\Theta^2+a^2\sigma_X^2+2cov(\Theta,-aX)=\sigma_\Theta^2+a^2\sigma_X-2a\cdot cov(\Theta,X)$. </li>
<li>To minimize $var(\Theta-aX)$, we set its derivative to zero and solve for $a$. This yields $a=\displaystyle\frac{cov(\Theta,X)}{\sigma^2_X}=\frac{\rho\sigma_\Theta\sigma_X}{\sigma^2_X}=\rho\frac{\sigma_\Theta}{\sigma_X}$, where $\rho=\displaystyle\frac{cov(\Theta,X)}{\sigma_\Theta\sigma_X}$. </li>
<li>The mean squared estimation error of the resulting linear estimator $\hat\Theta$ is given by $var(\Theta-\hat\Theta)=(1-\rho^2)\sigma^2_\Theta$. </li>
</ol>
<h4 id="Multiple-Observations-and-Multiple-Parameters"><a href="#Multiple-Observations-and-Multiple-Parameters" class="headerlink" title="Multiple Observations and Multiple Parameters"></a>Multiple Observations and Multiple Parameters</h4><ol>
<li>To minimize $E[(\Theta_1-\hat\Theta_1)^2]+…+E[(\Theta_m-\hat\Theta_m)^2]$, only need to minmize each $E[(\Theta_1-\hat\Theta_i)^2]$. So we are essentially dealing with $m$ decoupled linear estimation problems, one for each unknown parameter. </li>
<li>For every observation, we have $X_i=\Theta+W_i$, where the $W_i$ are random variables with mean $0$ and variance $\sigma_i^2$, which represent observation errors. </li>
<li>The linear LMS estimator of $\Theta$ based on the observations $X_1,…,X_n$ turns out to be $\hat\Theta_i=\displaystyle\frac{\displaystyle\frac{\mu_i}{\sigma_{0i}^2}+\displaystyle\sum^n_{i=1}\frac{X_i}{\sigma^2_i}}{\displaystyle\sum^n_{i=0}\frac{1}{\sigma^2_i}}$. $\mu_i$ is the mean of $\Theta_i$ while $\sigma_{0i}^2$ is the variance of $\Theta_i$. </li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2020/03/20/13-Central-Limit-Theorem-and-Strong-Law-of-Large-Numbers/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/20/13-Central-Limit-Theorem-and-Strong-Law-of-Large-Numbers/" class="post-title-link" itemprop="url">13. Central Limit Theorem and Strong Law of Large Numbers</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-03-20 17:52:34" itemprop="dateCreated datePublished" datetime="2020-03-20T17:52:34+08:00">2020-03-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-03-21 10:36:32" itemprop="dateModified" datetime="2020-03-21T10:36:32+08:00">2020-03-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Mathematics/" itemprop="url" rel="index">
                    <span itemprop="name">Mathematics</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Mathematics/Probability-MIT-6-041/" itemprop="url" rel="index">
                    <span itemprop="name">Probability (MIT 6.041)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="The-Central-Limit-Theorem"><a href="#The-Central-Limit-Theorem" class="headerlink" title="The Central Limit Theorem"></a>The Central Limit Theorem</h1><ol>
<li>While $M_n=\displaystyle\frac{X_1+…+X_n}{n}$ converges to the true mean $\mu$, $S_n=nM_n$ increases to infinity. </li>
<li>Consider the deviation $S_n-n\mu$ of $S_n$ from its mean $n\mu$, and scaling it by a factor proportional to $\displaystyle\frac{1}{\sqrt{n}}$ to keep the variance at a constant level. <br />We define $Z_n=\displaystyle\frac{S_n-n\mu}{\sigma\sqrt{n}}$. <br />So $E[Z_n]=\displaystyle\frac{E[X_1+…+E_n]-n\mu}{\sigma\sqrt{n}}$ and $var(Z_n)=\displaystyle\frac{var(X_1+…+X_n)}{\sigma^2n}=\frac{var(X_1)+…+var(X_n)}{\sigma^2n}=\frac{n\sigma^2}{n\sigma^2}=1$. </li>
<li>The central limit theorem: The CDF of $Z_n$ converges to the standard normal CDF in the sense that $\displaystyle\lim_{n\to\infty}P(Z_n≤z)=\Phi(z)$, for all $z$. </li>
<li>This law indicates that the sum of a large number of independent random variables is approximately normal. </li>
<li>This law eliminates the need for detailed probabilistic models, and for tedious manipulations of PMFs and PDFs. </li>
<li>Since normality is preserved uner linear transformations, this is equal to treating $S_n$ as a normal random variable with mean $n\mu$ and variance $\sigma^2$. </li>
<li>Let $z=\displaystyle\frac{c-n\mu}{\sigma\sqrt{n}}$. $P(S_n≤c)\approx\Phi(z)$. </li>
</ol>
<h1 id="De-Moivre-Laplace-Approximation-to-the-Binomial"><a href="#De-Moivre-Laplace-Approximation-to-the-Binomial" class="headerlink" title="De Moivre-Laplace Approximation to the Binomial"></a>De Moivre-Laplace Approximation to the Binomial</h1><ol>
<li>A binomial random variable $S_n$ with parameters $n$ and $p$ can be viewed as the sum of $n$ independent Bernoulli random variables $X_1,…,X_n$, with common parameter $p$. </li>
<li>$k≤S_n≤l\Longleftrightarrow\displaystyle\frac{k-np}{\sqrt{np(1-p)}}≤\frac{S_n-np}{\sqrt{np(1-p)}}≤\frac{l-np}{\sqrt{np(1-p)}}$. <br />$\displaystyle P(k≤S_n≤l)=P\left(\displaystyle\frac{k-np}{\sqrt{np(1-p)}}≤\frac{S_n-np}{\sqrt{np(1-p)}}≤\frac{l-np}{\sqrt{np(1-p)}}\right)\approx\Phi\left(\frac{l-np}{\sqrt{np(1-p)}}\right)-\Phi\left(\frac{k-np}{\sqrt{np(1-p)}}\right)$</li>
<li>An approximation of this form is equivalent to treat $S_n$ as a normal random variable with mean $np$ and variance $np(1-p)$. </li>
<li>A little bug in this approximation is that the approximation of $P(S_n=k)=P(k≤S_n≤k)$ is always zero. So we can fix by calculating with $k-\displaystyle\frac12$ and $l+\displaystyle\frac12$. This is the DeMoivre-Laplace approximation to the Binomial: <br />$\displaystyle P(k≤S_n≤l)\approx\Phi\left(\frac{l+\frac12-np}{\sqrt{np(1-p)}} \right)-\Phi\left(\frac{k-\frac12-np}{\sqrt{np(1-p)}} \right)$</li>
</ol>
<h1 id="The-Strong-Law-of-Large-Numbers"><a href="#The-Strong-Law-of-Large-Numbers" class="headerlink" title="The Strong Law of Large Numbers"></a>The Strong Law of Large Numbers</h1><ol>
<li>Let $X_1,X_2,…$ be a sequence of independent identically distributed random variables with mean $\mu$. Then the sequence of sample means converges to $\mu$, with probability $1$, in the sense that $P\left(\displaystyle\lim_{n\to\infty}\frac{X_1+…X_2}{n}=\mu\right)=1$. </li>
<li>Consider the experiment is infinitely long , so the sample space is a set of infinite sequences of real number. Let set $A$ consist of those sequences whose long-term average is $\mu$. The strong law of large numbers states that all of the probability is concentrated on this particular subset of the sample space. </li>
<li>The collection of outcomes that do not belong to $A$ has probability zero. </li>
<li>The weak law provides no conclusive information on the number of deviations between $M_n$ and $\mu$ as $n$ tends to infinity. The strong law implies that  for any given $\epsilon&gt;0$, the probability that the difference $|M_n-\mu|$ will exceed $\epsilon$ an infintie number of times is equal to zero. </li>
<li>Convergence with probability: $Y_1,Y_2,…$ are a sequence of random variables (not necessarily independent). $c$ is a real number. $Y_n$ converges to $c$ with probability $1$ if $P\left(\displaystyle\lim_{n\to\infty}Y_n=c\right)=1$. </li>
<li>Convergence WITH probabiltiy is different from convergence IN probability. </li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2020/03/20/12-Weak-Law-of-Large-Numbers/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/20/12-Weak-Law-of-Large-Numbers/" class="post-title-link" itemprop="url">12. Weak Law of Large Numbers</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-03-20 11:12:37" itemprop="dateCreated datePublished" datetime="2020-03-20T11:12:37+08:00">2020-03-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-03-21 10:39:23" itemprop="dateModified" datetime="2020-03-21T10:39:23+08:00">2020-03-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Mathematics/" itemprop="url" rel="index">
                    <span itemprop="name">Mathematics</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Mathematics/Probability-MIT-6-041/" itemprop="url" rel="index">
                    <span itemprop="name">Probability (MIT 6.041)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Inequalities"><a href="#Inequalities" class="headerlink" title="Inequalities"></a>Inequalities</h1><ol>
<li>Markov inequality: If a random variable $X$ can only take nonnegative values, then $P(X≥a)≤\displaystyle\frac{E[X]}{a}$, for all $a&gt;0$. <br />Proof: <br />&emsp;First fix a positive number $a$ and let <script type="math/tex">Y_a=\left\{\begin{array}{}0&if\ X<a\\a&if\ X≥a \end{array}\right.</script>. <br />&emsp;So $Y_a≤X$ and therefore $E[Y_a]≤E[X]$. <br />&emsp;$E[Y_a]=aP(Y_a=a)=aP(X≥a)$. So $aP(X≥a)≤E[X]$. <br />&emsp;Hence, $P(X≥a)≤\displaystyle\frac{E[X]}{a}$. </li>
<li>If a nonnegative random variable has a small mean, then the probability that it takes a large value must also be small. </li>
<li>The bounds provided by the Markov inequality can be quite loose. </li>
<li>Chebyshev inequality: If $X$ is a random variable with mean $\mu$ and variance $\sigma^2$, $P(|X-\mu|≥c)≤\displaystyle\frac{\sigma^2}{c^2}$. <br />Proff: <br />&emsp;$P(|X-\mu|≥c)=P((X-\mu)^2≥c^2)≤\displaystyle\frac{E[(X-\mu)^2]}{c^2}=\frac{\sigma^2}{c^2}$. </li>
<li>Let $c=k\sigma$, $P(|X-\mu|≥k\sigma)≤\displaystyle\frac{\sigma^2}{k^2\sigma^2}=\frac{1}{k^2}$. </li>
<li>The bounds that the Chebyshev inequality provides are more accurate than Markkov inequality. But we still cannot expect the bounds to be close approximations of the exact probabilities. </li>
</ol>
<h1 id="The-Weak-Law-of-Large-Numbers"><a href="#The-Weak-Law-of-Large-Numbers" class="headerlink" title="The Weak Law of Large Numbers"></a>The Weak Law of Large Numbers</h1><ol>
<li>A sequence $X_1,X_2,…$ of independent identically distributed random vairables with mean $\mu$ and variance $\sigma^2$ and define the sample mean by $M_n=\displaystyle\frac{X_1+…+X_n}{n}$. <br />We have $E[M_n]=\displaystyle\frac{E[X_1]+…+E[X_n]}{n}=\frac{n\mu}{n}=\mu$, and $var(M_n)=\displaystyle\frac{var(X_1+…X_n)}{n^2}=\frac{var(X_1)+…+var(X_n)}{n^2}=\frac{n\sigma^2}{n}=\frac{\sigma^2}{n}$. </li>
<li>Apply the Chebyshev inequality and obtain $P(|M_n-\mu|≥\epsilon)≤\displaystyle\frac{\sigma^2}{n\epsilon^2}$, for any $\epsilon&gt;0$. </li>
<li>The weak law of large numbers: For every $\epsilon&gt;0$, we have $P(|M_n-\mu|≥\epsilon)=P\left(\left|\displaystyle\frac{X_1+…+X_n}{n}-\mu\right|≥\epsilon\right)\to0$, as $n\to\infty$. </li>
<li>For large $n$, the bulk of the distribution of $M_n$ is concentrated near $\mu$. If we consider a positive length interval $[\mu-\epsilon,\mu+\epsilon]$ around $\mu$, then there is high probability that $M_n$ will fall in that interval; as $n\to\infty$, this probability converges to $1$. If $\epsilon$ is very small, we may have to wait longer (i.e.need a larger value of $n$). </li>
</ol>
<h1 id="Convergence-in-Probability"><a href="#Convergence-in-Probability" class="headerlink" title="Convergence in Probability"></a>Convergence in Probability</h1><ol>
<li>Convergence in Probability: Let $Y_1,Y_2,…$ be a sequence of random variables (not necessarily independent), and let $a$ be a real number. We say that the sequence $Y_n$ converges to $a$ in probability, if for every $\epsilon&gt;0$, we have $\displaystyle\lim_{n\to\infty}P(|Y_n-a|≥\epsilon)=0$. </li>
<li>The weak law of large numbers simply states that the sample mean converges in probability to the true mean $\mu$. </li>
<li>The Chebyshev inequality implies that if all $Y_n$ have the same mean $\mu$, and $var(Y_n)$ converges to $0$, then $Y_n$ converges to $\mu$ in probability. </li>
<li>If the random variables $Y_1,Y_2,…$ have a PMF or a PDF and converge in probability to $a$, then according to the above definition, “almost all” of the PMF or PDF of $Y_n$ is concentrated within $\epsilon$ of $a$ for large values of $n$. </li>
<li>The definition can be rephrased as: For every $\epsilon&gt;0$, and for every $\delta&gt;0$, there exists some $n_0$ such that $P(|Y_n-a|≥\epsilon)≤\delta$, for all $n≥n_0$. </li>
<li>If we refer to $\epsilon$ as the accuracy level, and $\delta$ as the confidence level, for any given level of accuracy and confidenc, $Y_n$ will be equal to $a$, within these levels of accuracy and confidence, provided that $n$ is large enough. </li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2020/03/17/11-Markov-Chains/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/17/11-Markov-Chains/" class="post-title-link" itemprop="url">11. Markov Chains</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-03-17 15:43:13" itemprop="dateCreated datePublished" datetime="2020-03-17T15:43:13+08:00">2020-03-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-03-19 18:36:14" itemprop="dateModified" datetime="2020-03-19T18:36:14+08:00">2020-03-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Mathematics/" itemprop="url" rel="index">
                    <span itemprop="name">Mathematics</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Mathematics/Probability-MIT-6-041/" itemprop="url" rel="index">
                    <span itemprop="name">Probability (MIT 6.041)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Discrete-Time-Markov-Chains"><a href="#Discrete-Time-Markov-Chains" class="headerlink" title="Discrete-Time Markov Chains"></a>Discrete-Time Markov Chains</h1><ol>
<li>The effect of the past on the future is summarized by state, which changes over time according to given probabilities. </li>
<li>In discrete-time markoc chains, state changes ar certain discrete time instants, indexed by an integer variable $n$. </li>
<li>At each time step $n$, the state of the chain is denoted by $X_n$ and belongs to a finite set $S$ of possible states, called the state space. <br />We assume that $S=\{1,…,m\}$, for some positive integer $m$. </li>
<li>The Markov chain is described in terms of its transition probabilities $p_{ij}$: whenever the state happens to be $i$, there is a probability $p_{ij}$ that the next state is equal to $j$. Mathematically, $p_{ij}=P(X_{n+1}=j|X_n=i), (i,j\in S)$. </li>
<li>The transition probabilities apply whenever state $i$ is visited, no matter what happened in the past and no matter how state $i$ was reached. <br />The Markov property requires $P(X_{n+1}=j|X_n=i,X_{n-1}=i_n-1,…,X_0=i_0)=P(X_{n+1}=j|X_n=i)=p_{ij}$, for all time $n$, all states $i,j\in S$ and all sequences $i_0,…,i_{n-1}$ of earlier states. <br />Thus, the probability law of the next state $X_{n-1}$ depends on the past only through the value of the present state $X_n$. </li>
<li>For all states, $\displaystyle\sum^m_{j=1}p_{ij}=1, \forall i$. </li>
<li>The probability $p_{ii}$ is allowed to be positive, in which case it’s possible for the next state to be the same as the current one. Even though the state doesn’t change, we still view this as a state stransition of a special type (a “self-transition”). </li>
<li>All of the elements of a Markov chain model can be encoded in a transition probability matrix. </li>
<li>It’s also helpful to lay out the model in the socalled transition probability graph, whose nodes are the states and whose arcs are the possible transitions. </li>
<li>It’s possible to use a Markov chain model even if there is a dependence on the states at several past days. The general idea is to introduce some additional states which encode relevant information from preceding periods. </li>
<li>$P(X_0=i_0,X_1=i_1,…,X_n=i_n)=P(X_0=0)p_{i_0i_1}p_{i_1i_2}…p_{i_{n-1}i_n}$<br />$P(X_1=i_1,…,X_n=i_n|X_0=i_0)=p_{i_0i_1}p_{i_1i_2}…p_{i_{n-1}i_n}$</li>
<li>Graphically, a state sequence can be identified with a sequence of arcs in the transition probability graph, and the probability of such a path (given the initial state) is given by the product of the probabilities associated with the arcs traversed by the path. </li>
</ol>
<h1 id="n-step-Transition-Probabilities"><a href="#n-step-Transition-Probabilities" class="headerlink" title="n-step Transition Probabilities"></a>n-step Transition Probabilities</h1><ol>
<li>$n$-step transition probabilities are probabilities that describe the likelihood of the state at some  future time, conditioned on the current state. </li>
<li>This is defined by $r_{ij}(n)=P(X_n=j|X_0=i)$. This is the probability that the state after $n$ time periods will be $j$, given that the current state is $i$. </li>
<li>Chapman_Kolmogorov equation: $r_{ij}(n)=\displaystyle\sum^m_{k=1}r_{ik}(n-1)p_{kj}$, for $n&gt;1$ and all $i,j$. Start with $r_{ij}(1)=p_{ij}$. <br />Namely the sum of the product of the probability of $n-1$ steps later at state $k$ and the probability of from $k$ to $j$. <br />The trick is that once we condition on $X_{n-1}=k$, the conditioning on $X_0=i$ does not affect the probability $p_{kj}$ of reaching $j$ at the next step. </li>
<li>We can view $r_{ij}(n)$  as the element at the $i$th row and $j$th column of $n$-step transition probability matrix. </li>
<li>The matrix of $n$-step transition probabilities $r_{ij}(n)$ is obtained by multiplying the $i$th row of matrix of $(n-1)$-step transition probability $r_{ik}(n-1)$, with the $j$th column of one-step transition probability matrix $p_{kj}$. <br />Thus, the $n$-step transition probability matrix is the $n$th power of the transition probability matrix. </li>
</ol>
<h1 id="Recurrent-and-Transient"><a href="#Recurrent-and-Transient" class="headerlink" title="Recurrent and Transient"></a>Recurrent and Transient</h1><ol>
<li>A state $j$ is accessible from a state $i$ if for some $n$, the $n$-step transition probability $r_{ij}(n)$ is positive. </li>
<li>Let $A(i)$ be the set of states that are accessible from $i$. </li>
<li>We say that $i$ is recurrent if for every $j$ that is accessible from $i$, $i$ is also accessible from $j$. Namely for all $j$ that belong to $A(i)$ , we have that $i$ belongs to $A(j)$. </li>
<li>From any future state, there is always som probability of returning to $i$ and , given enough time, this is certain to happen. </li>
<li>If a recurrent state is visited once, it’s certain to be revisited an infinite number of times. </li>
<li>If a state is not recurrent, then it is called transient. Thus, a state $i$ is transient if there is a stete $j\in A(i)$ such that $i$ is not accessible from $j$. <br />After each visit to state $i$, there is positive probability that the state enters such a $j$. Given enough time, this will happen, and state $i$ cannot be visited after that. Thus, a transient state will only be visited a finite number of times. </li>
<li>Transient or recurrent is determined by the arcs of the transition probability graph (wheter $p_{ij}&gt;0$) and not by the numerical values of the $p_{ij}$. </li>
<li>If $i$ is a recurrent state, the set of states $A(i)$ that are accessible from $i$ form a recurrent class, meaning that states in $A(i)$ are all accessible from each other, and no state outside $A(i)$ is accessible from them. <br />For a recurrent state $i$, we have $A(i)=A(j)$ for all $j$ that belong to $A(i)$. </li>
<li>At least one recurrent state must be accessible from any given transient state. <br />A recurrent state is accessible from all states in its class, but is not accessible from recurrent states in other classes. <br />A transient state is not accessible from any recurrent state. </li>
<li>There must exist at least one recurrent state and hence at least one class. </li>
<li>A Markov chain can be decomposed into one or more recurrent classes, plus possibly some transient states. </li>
<li>Once the state enters (or starts in) a class of recurrent states, it stays within that class; since all states in the class are accessible from each other, all states in the class will be visited an infinite number of times. </li>
<li>If the initial state is transient, then the state trajectory contains an initial portion consisting of transient states and a final portion consisting of recurrent states from the same class. </li>
</ol>
<h1 id="Periodicity"><a href="#Periodicity" class="headerlink" title="Periodicity"></a>Periodicity</h1><ol>
<li>A recurrent class is said to be periodic if its states can be grouped in $d&gt;1$ disjoint subsets $S_1,…,S_d$ so that all transitions from one subset lead to the next subset. <br />If $i\in S$ and $p_{ij}&gt;0$, then <script type="math/tex">\left\{\begin{array}{}j\in S_{k+1} & if\ k=1,…,d-1\\j\in S_1&if\ k=d \end{array}\right.</script>. </li>
<li>A recurrent class that is not periodic is said to be aperiodic. </li>
<li>In a periodic recurrent class, we move through that sequence of subsets in order, and after $d$ steps, we end up in the same subset. </li>
<li>Given a periodic recurrent class, a positive time $n$, and a state $i$ in the class, there must exist one or more states $j$ for which $r_{ij}(n)=0$. <br />Starting from $i$, only one of the sets is possible at time $n$. </li>
<li>A way to verify aperiodicity of a given recurrent class $R$, is to check whether there is a special time $n≥1$ and a special state $i\in R$ from which all states in $R$ can be reached in $n$ steps, i.e. $r_{ij}(n)&gt;0$ for all $j\in R$. </li>
<li>If a recurrent class $R$ is aperiodic, then there exists a time $n$ such that $r_{ij}(n)&gt;0$ for every $i$ and $j$ in $R$. </li>
</ol>
<h1 id="Steady-State-Behavior"><a href="#Steady-State-Behavior" class="headerlink" title="Steady-State Behavior"></a>Steady-State Behavior</h1><ol>
<li>If there are two or more classes of recurrent states, it is clear that the limiting values of the $r_{ij}(n)$ must depend on the initial state (the possibility of visiting $j$ far into the future depends on whether $j$ is in the same class as the initial state $i$). </li>
<li>Even for chains with a single recurrent class, the $r_{ij}(n)$ may fail to converge. </li>
<li>The recurrent class is periodic, and for such a class, it can be seen that the $r_{ij}(n)$ generically oscillate. </li>
<li>For every state $j$, the probability $r_{ij}(n)$ of being at state $j$ approaches a limiting value that is independent of the initial state $i$. This limiting value, denoted by $\pi_j$, has the interpretation $\pi_j\approx P(X_n=j)$, when $n$ is large, and is called the steady-state probability of $j$. </li>
<li>For a Markov chain with a single recurrent class, which is aperiodic, <br />&emsp;for each $j$, we have $\displaystyle\lim_{i\to\infty}r_{ij}(n)=\pi_j$, for all $i$; <br />&emsp;The $\pi_j$ are unique solution to the system of equation <script type="math/tex">\displaystyle\left\{\begin{array}{}the\ balance\ equations:& \pi_j=\sum^n_{k=1}\pi_kp_{kj}&j=1,…,m\\the\ normalization\ equation:&1=\sum^m_{k=1}\pi_k \end{array}\right.</script><br />&emsp;We have <script type="math/tex">\left\{\begin{array}{}\pi_j=0 &for\ all\ transient\ states\ j\\\pi_j>0&for\ all\ recurrent\ states\ j\end{array}\right.</script>. </li>
<li>The steady-state probabilities $\pi_j$ sum to $1$ and form a probability distribution on the state space, called the stationary distribution of the chain. <br />If the initial state is chosen according to this distribution, i.e. if $P(X_0=j)=\pi_j, j=1,…,m$, then, using the total probability theorem, we have $P(X_1=j)=\displaystyle\sum^m_{k=1}P(X_0=k)p_{kj}=\sum^m_{k=1}\pi_kp_{kj}=\pi_j$. <br />Similarly $P(X_n=j)=\pi_j$, for all $n$ and $j$. </li>
</ol>
<h1 id="Long-Term-Frequency-Interpretations"><a href="#Long-Term-Frequency-Interpretations" class="headerlink" title="Long-Term Frequency Interpretations"></a>Long-Term Frequency Interpretations</h1><ol>
<li>Two way to view the long-term expected value: <br />&emsp;One way is to view it as the expected value of the number on a randomly chosen day far into the future. <br />&emsp;Another way is to calculate the total expected value of the number in $n$ days, where $n$ is very large, and divide it by $n$. </li>
<li>For a Markov chain with a single class which is aperiodic, the steady-state probabilities $\pi_j$ satisfy $\pi_j=\displaystyle\lim_{n\to\infty}\frac{v_{ij}(n)}{n}$, where $v_{ij}(n)$ is the expected value of the number of visits to state $j$ within the first $n$ transitions, starting from state $i$. </li>
<li>$\pi_j$ is the long-term expected fraction of time that the state is equal to $j$. Each time that state $j$ is visited, there is probability $p_{jk}$ that the next transition takes up to state $k$. We conclude that $\pi_kp_{jk}$ can be viewed as the long-term expected fraction of transitions that move the state from $j$ to $k$. </li>
<li>Whenever we carry out a probabilistic experiment and generate a trajectory of the Markov chain over an infinite time horizon, the observed long-term frequency with which state $j$ is visited will be exactly equal to $\pi_j$, and the observed long-term frequency of transitions from $j$ to $k$ will be exactly equal to $\pi_jp_{jk}$. </li>
<li>For $n$ transitions of a Markov chain with a single class which is aperiodic, let $q_{jk}(n)$ be the expected number of such transitions that take the state from $j$ to $k$. Then regardless of the initial state, we have $\displaystyle\lim_{n\to\infty}\frac{q_{jk}(n)}{n}=\pi_jp_{jk}$. </li>
<li>Now we can see that the balance equation expresses the fact that the expected frequency $\pi_j$ of visits to $j$ is equal to the sum of the expected frequencies $\pi_kp_{kj}$ of the transition that lead to $j$. </li>
</ol>
<h1 id="Birth-Death-Process"><a href="#Birth-Death-Process" class="headerlink" title="Birth-Death Process"></a>Birth-Death Process</h1><ol>
<li>A birth-death process is a Markov chain in which the states are linearly arranged and transitions can only occur to a neighboring state, or else leave the state unchanged. <br />$b_i=P(X_{n+1}=i+1|X_n=i)$, (“birth” probability at state $i$), <br />$d_i=P(X_{n+1}=i-1|X_n=1)$, (“death” probability at state $i$). </li>
<li>In any trajectory of the Markov chain, a transition from $i$ to $i+1$ has to be followed by a transition from $i+1$ to $i$, before another transition from $i$ to $i+1$ can occur. </li>
<li>The expected frequency of transitions from $i$ to $i+1$, which is $\pi_ib_i$, must be equal to the expected frequency of transitions from $i+1$ to $i$, which is $\pi_{i+1}d_{i+1}$. This leads to the local balance equations $\pi_ib_i=\pi_{i+1}d_{i+1}$, $i=0,1,…,m-1$. </li>
<li>Using the local balance equations, we obtain $\pi_i=\pi_0\displaystyle\frac{b_0b_2…b_{i-1}}{d_1d_2…d_i}$, $i=1,…,m$. </li>
<li>If $b_i=p,d_i=q$ for all $i$, <script type="math/tex">\rho=\displaystyle\frac{p}{q}=load\ factor≠1</script>, there are $m$ states. <br />$\pi_{i+1}=\pi_i\displaystyle\frac{p}q=\pi_i\rho$. So $\pi_i=\pi_0\rho^i$, $i=0,1,…,m$. <br />$1=\displaystyle\sum^m_{i=0}\pi_i=\pi_0(1+\rho+…+\rho^m)$. So $\pi_0=\displaystyle\frac{1-\rho}{1-\rho^{m+1}}$<br />If $p<q$, $\rho<1$ and $m\to\infty$. Then $\pi_0=1-p$ $\pi_i=(1-\rho)\rho^i$, $E[X_n]=\displaystyle\frac{\rho}{1-\rho}$. <br />If $p&gt;q$, $\rho&gt;1$ and $m\to\infty$. Then $\pi_i\to0$, for all $i$. </li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2020/03/16/10-Poisson-Porcess/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/16/10-Poisson-Porcess/" class="post-title-link" itemprop="url">10. Poisson Porcess</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-03-16 23:41:53" itemprop="dateCreated datePublished" datetime="2020-03-16T23:41:53+08:00">2020-03-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-03-17 23:27:43" itemprop="dateModified" datetime="2020-03-17T23:27:43+08:00">2020-03-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Mathematics/" itemprop="url" rel="index">
                    <span itemprop="name">Mathematics</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Mathematics/Probability-MIT-6-041/" itemprop="url" rel="index">
                    <span itemprop="name">Probability (MIT 6.041)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h1><ol>
<li>The Poisson process is a continuous-time analog of the Bernoulli process. </li>
<li><script type="math/tex">\lambda</script> is the rate of one Poisson process. Namely the rate of arrivals per unit time. </li>
<li>We define <script type="math/tex">P(k,\tau)=P(there\ are\ exactly\ k\ arrivals\ during\ an\ interval\ of\ length\ \tau)</script></li>
<li>This probability is the same for all intervals of the same length <script type="math/tex">\tau</script>. Namely, arrivals are equally likely ar all times. </li>
<li>The number of arrivals during a particular interval is independent of the history of arrivals outside this interval. </li>
<li><script type="math/tex">P(0,\tau)=1-\lambda\tau+o(\tau)</script><br /><script type="math/tex">P(1,\tau)=\lambda\tau+o_1(\tau)</script><br /><script type="math/tex">P(k,\tau)=o_k(\tau)\ \ (k>1)</script>. <br /><script type="math/tex">\displaystyle\lim_{\tau\to0}\frac{o(\tau)}{\tau}=0</script>, <script type="math/tex">\displaystyle\lim_{\tau\to0}\frac{o_k(\tau)}{\tau}</script>. </li>
<li>The <script type="math/tex">o(\tau)</script> and <script type="math/tex">o_k(\tau)</script> are meant to be negligible in comparison to <script type="math/tex">\tau</script>, when the interaval length <script type="math/tex">\tau</script> is very small. </li>
</ol>
<h1 id="Number-of-Arrivals-in-an-Interval"><a href="#Number-of-Arrivals-in-an-Interval" class="headerlink" title="Number of Arrivals in an Interval"></a>Number of Arrivals in an Interval</h1><ol>
<li>First fix the time interval of length <script type="math/tex">\tau</script> and partition it into <script type="math/tex">\displaystyle\frac{\tau}{\delta}</script> periods of length <script type="math/tex">\delta</script>, where <script type="math/tex">\delta</script> is a very small number. </li>
<li>Because <script type="math/tex">P(k,\tau)=o_k(\tau)</script> when <script type="math/tex">k≥2</script>, the probability of more than two arrivals during any period can be neglected. </li>
<li>Each period has one arrival with probability approximately equal to <script type="math/tex">\lambda\delta</script> and is independent of each other. </li>
<li>Therefore, the process can be approximated by a Bernoulli process with parameter <script type="math/tex">\lambda\delta</script>. </li>
<li>Hence, the PMF is <script type="math/tex">P(k,\tau)=e^{-\lambda\tau}\displaystyle\frac{(\lambda\tau)^k}{k!}</script>, the expected number of arrivals is <script type="math/tex">E[N\tau]=np=\lambda\tau</script> and the variance is <script type="math/tex">var(N_\tau)=\lambda\tau</script>. <script type="math/tex">N_\tau</script> denotes the number of arrivals during a time interval of length <script type="math/tex">\tau</script>. </li>
<li>The probability law for the time <script type="math/tex">T</script> of the first arrival, assuming that the process starts at time zero: <br /><script type="math/tex">F_T(t)=P(T≤t)=1-P(T>t)=1-P(0,t)=1-e^{-\lambda t}</script>. </li>
<li>The PDF formula: <script type="math/tex">f_T(t)=\lambda e^{-\lambda t}</script> <script type="math/tex">(t≥0)</script>. </li>
<li>The probability of <script type="math/tex">k</script> arrivals during a set of times of total length <script type="math/tex">\tau</script> is always given by <script type="math/tex">P(k,\tau)</script>, even if that set is not an interval. </li>
</ol>
<h1 id="Independence-and-Memorylessness"><a href="#Independence-and-Memorylessness" class="headerlink" title="Independence and Memorylessness"></a>Independence and Memorylessness</h1><ol>
<li>For any given time <script type="math/tex">t>0</script>, the history of the process after time <script type="math/tex">t</script> is also a Poisson process, and is independent from the history of the process until <script type="math/tex">t</script>. </li>
<li>Let <script type="math/tex">t</script> be a given time and let <script type="math/tex">\overline{T}</script> be the time of the first arrival after time <script type="math/tex">t</script>. Then <script type="math/tex">\overline{T}-t</script> has an exponential distribution with parameter <script type="math/tex">\lambda</script>, and is independent of the history of the process until time <script type="math/tex">t</script>. </li>
</ol>
<h1 id="The-kth-Arrival-Time"><a href="#The-kth-Arrival-Time" class="headerlink" title="The kth Arrival Time"></a>The kth Arrival Time</h1><ol>
<li>The definition is the same as in the Bernoulli process. </li>
<li>$E[Y_k]=E[T_1]+…+E[T_k]=\displaystyle\frac{k}{\lambda}$</li>
<li>$var(Y_k)=var(T_1)+…+var(T_k)=\displaystyle\frac{k}{\lambda^2}$</li>
<li>The PDF of <script type="math/tex">Y_k</script> (Erlang PDF of order <script type="math/tex">k</script>) is <script type="math/tex">f_{Y_k}(y)=\displaystyle\frac{\lambda^ky^{k-1}e^{-\lambda y}}{(k-1)!}\ \ (y≥0)</script>. </li>
<li>For a small <script type="math/tex">\delta</script>, the product <script type="math/tex">\delta\cdot f_{Y_k}(y)</script> approximates the probability that the <script type="math/tex">k</script>th arrival occurs between times <script type="math/tex">y</script> and <script type="math/tex">y+\delta</script>. </li>
<li>When <script type="math/tex">\delta</script> is very small, the probability of more thant one arrival during the interval <script type="math/tex">[y,y+\delta]</script> is negligible. Thus the <script type="math/tex">k</script>th arrival occurs between <script type="math/tex">y</script> and <script type="math/tex">y+\delta</script> if and only if: <br />&emsp;There is an arrival during the interval <script type="math/tex">[y,y+\delta]</script><br />&emsp;There are exactly <script type="math/tex">k-1</script> arrivals before time <script type="math/tex">y</script>. <br /><script type="math/tex">\delta f_{Y_k}(y)\approx \lambda\delta \cdot P(k-1,y)=\lambda\delta\displaystyle\frac{\lambda^{k-1}y^{k-1}e^{-\lambda y}}{(k-1)!}</script><br />So <script type="math/tex">f_{Y_k}(y)=\displaystyle\frac{\lambda^ky^{k-1}e^{-\lambda y}}{(k-1)!}</script></li>
<li>CDF: <script type="math/tex">F_{Y_k}(y)=P(Y_k≤y)=\displaystyle\sum^\infty_{n=k}P(n,y)=1-\sum^{k-1}_{n=0}P(n,y)=1-\sum^{k-1}_{n=0}\frac{(\lambda y)^ne^{-\lambda y}}{n!}</script></li>
</ol>
<h1 id="Splitting-and-Merging"><a href="#Splitting-and-Merging" class="headerlink" title="Splitting and Merging"></a>Splitting and Merging</h1><ol>
<li>As in the Bernoulli process, start with one Poisson process with rate <script type="math/tex">\lambda</script> and split its arrivals at rate <script type="math/tex">q</script> into two independent new processes with new rates <script type="math/tex">\lambda q</script> and <script type="math/tex">\lambda(1-q)</script>. </li>
<li>Alternatively, start with two Poisson processes with rates <script type="math/tex">\lambda_1</script> and <script type="math/tex">\lambda_2</script> and merge them into one process with rate <script type="math/tex">\lambda_1+\lambda_2</script>. <br/><script type="math/tex">P(0\ arrivals\ in\ the\ merged\ process)\approx(1-\lambda_1\delta)(1-\lambda_2\delta)\approx1-(\lambda_1+\lambda_2)\delta</script><br /><script type="math/tex">P(1\ arrivals\ in\ the\ merged\ process)\approx\lambda_1\delta(1-\lambda_2\delta)+(1-\lambda_1\delta)\lambda_2\delta\approx(\lambda_1+\lambda_2)\delta</script></li>
<li>Any particular arrival of the merged process has probability <script type="math/tex">\displaystyle\frac{\lambda_1}{\lambda_1+\lambda_2}</script> of originating from the first process, and probability <script type="math/tex">\displaystyle\frac{\lambda_2}{\lambda_1+\lambda_2}</script> of originating from the second process. <br /><script type="math/tex">P(1\ arrival\ of\ first\ process|1\ arrival)=\displaystyle\frac{P(1\ arrival\ of\ first\ process)}{P(1\ arrival)}\approx\frac{\lambda_1\delta}{(\lambda_1+\lambda_2)\delta}=\frac{\lambda_1}{\lambda_1+\lambda+2}</script></li>
</ol>
<h1 id="Sums-of-Random-Variables"><a href="#Sums-of-Random-Variables" class="headerlink" title="Sums of Random Variables"></a>Sums of Random Variables</h1><ol>
<li>Let <script type="math/tex">N,X_1,X_2,…</script> be independent random variables. <script type="math/tex">N</script> takes nonnegative integer values. Let <script type="math/tex">Y=X_1+…+X_N</script>. <script type="math/tex">Y=0</script> when <script type="math/tex">N=0</script>. </li>
<li>If <script type="math/tex">X_i</script> is Bernoulli with parameter <script type="math/tex">p</script>, and <script type="math/tex">N</script> is binomial with parameters <script type="math/tex">m</script> and <script type="math/tex">q</script>, then <script type="math/tex">Y</script> is binomial with parameters <script type="math/tex">m</script> and <script type="math/tex">pq</script>. </li>
<li>If <script type="math/tex">X_i</script> is Bernoulli with parameter <script type="math/tex">p</script> and <script type="math/tex">N</script> is Poisson with parameter <script type="math/tex">\lambda</script>, then <script type="math/tex">Y</script> is Poisson with parameter <script type="math/tex">\lambda p</script>. </li>
<li>If <script type="math/tex">X_i</script> is geometric with parameter <script type="math/tex">p</script>, and <script type="math/tex">N</script> is geometric with parameter <script type="math/tex">q</script>, then <script type="math/tex">Y</script> is geometirc with parametric <script type="math/tex">pq</script>. </li>
<li>If <script type="math/tex">X_i</script> is exponential with parameter <script type="math/tex">\lambda</script>, and <script type="math/tex">N</script> is geometric with parameter <script type="math/tex">q</script>, then <script type="math/tex">Y</script> is exponential with parameter <script type="math/tex">\lambda q</script>. </li>
<li>If <script type="math/tex">N_t</script> denotes the number of arrivals of a Poisson process with parameter <script type="math/tex">\lambda</script> within an interval of length <script type="math/tex">t</script>, and <script type="math/tex">T</script> is an interval with length that is exponentially distributed with parameter <script type="math/tex">\upsilon</script> and is independent of the Poisson process, then <script type="math/tex">N_T+1</script> is geometrically distributed with parameter <script type="math/tex">\displaystyle\frac{\upsilon}{\lambda+\upsilon}</script>. </li>
<li>The sum of a large number of independent arrival processes (not necessarily Poisson) can be approximated by a Poisson process with arrival rate equal to the sum of the individual arrival rates. <br />The component processes must have a small rate relative to the total, so that none of them imposes its probabilistic character on the total arrival process. </li>
</ol>
<h1 id="Random-Incidence-Paradox"><a href="#Random-Incidence-Paradox" class="headerlink" title="Random Incidence Paradox"></a>Random Incidence Paradox</h1><ol>
<li><script type="math/tex">t^*</script> is a fixed time instance with at least one prior arrival. <script type="math/tex">L</script> is the inter arrival interval that contains <script type="math/tex">t^*</script>. </li>
<li>Let <script type="math/tex">L</script> be <script type="math/tex">[U,V]</script>. Split <script type="math/tex">L</script> into two parts <script type="math/tex">L=(t^*-U)+(V-t^*)</script>. </li>
<li><script type="math/tex">t^*-U</script> is determined by the past history of the process before <script type="math/tex">t^*</script> while <script type="math/tex">V-t^*</script> is determined by the future of the process after time <script type="math/tex">t^*</script>. </li>
<li>These two are independent and both are exponential with parameter <script type="math/tex">\lambda</script>. So <script type="math/tex">L</script> is the sum of two independent exponential random variables with parameter <script type="math/tex">\lambda</script>, i.e. Erlang of order two, with mean <script type="math/tex">\displaystyle\frac{2}{\lambda}</script>. </li>
<li>This is not right, the mean should be <script type="math/tex">\displaystyle\frac{1}{\lambda}</script>. The problem is that when we insert that time instance <script type="math/tex">t^*</script> into time line, it is more likely to fall into larger intervals rather than  smaller intervals. So the expectation of the interval is larger. </li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/17/">17</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="LiyunZhang"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">LiyunZhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">164</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liyun Zhang</span>
</div>
<div class="BbeiAn-info">
       浙ICP备 -
    <a target="_blank" href="http://www.miitbeian.gov.cn/" style="color:#000000"  rel="nofollow">19047088号-1</a> <!--a标签中增加nofollow属性，避免爬虫出站。-->|
    <a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=33011802001835" style="color:#000000;text-decoration:none;padding-left:30px;background:url(https://s1.ax1x.com/2018/09/29/ilmwIH.png) no-repeat left center" rel="nofollow">浙公网安备 33011802001835号</a>      <!--这里将图标作为了背景，以使得能和后面的文字在同一行-->

</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

</body>
</html>
