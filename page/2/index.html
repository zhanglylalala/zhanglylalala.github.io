<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/avatar.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/avatar.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://http://www.laughingtree.cn').hostname,
    root: '/',
    scheme: 'Mist',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":true},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta property="og:type" content="website">
<meta property="og:title" content="LaughingTree">
<meta property="og:url" content="http://http//www.laughingtree.cn/page/2/index.html">
<meta property="og:site_name" content="LaughingTree">
<meta property="article:author" content="LiyunZhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://http//www.laughingtree.cn/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>LaughingTree</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">LaughingTree</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags<span class="badge">29</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories<span class="badge">33</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="Searching..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2022/06/28/08-Sampling/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2022/06/28/08-Sampling/" class="post-title-link" itemprop="url">08. Sampling</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-06-28 11:01:03 / Modified: 16:44:19" itemprop="dateCreated datePublished" datetime="2022-06-28T11:01:03+08:00">2022-06-28</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index">
                    <span itemprop="name">计算机科学与技术</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F-MIT-6-007/" itemprop="url" rel="index">
                    <span itemprop="name">信号与系统 (MIT 6.007)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Continuous-time-sampling"><a href="#Continuous-time-sampling" class="headerlink" title="Continuous-time sampling"></a>Continuous-time sampling</h1><ol>
<li><p>With $p(t)$ being impulse train, $x(t)p(t)$ is samples of $x(t)$.<br>Sampling theorem: given equally spaced samples of $x(t)$ and $x(t)$ is band limited ($X(\omega)=0$ for $|\omega|&gt;\omega_M$), if the sampling frequency $\omega_s=\frac{2\pi}{T}&gt;2\omega_M$, then $x(t)$ is uniquely recoverable with lowpass filter.<br>We can process continuous-time signal in the discrete-time way. </p>
</li>
<li><p>The condition $\omega_s&gt;2\omega_M$ is to avoid overlap in frequency domain. If $\omega_s&lt;2\omega_M$, aliasing will cause errors in reconstructing signals. Aliasing will reconstruct a low frequency signal instead of the real high frequency signal. </p>
</li>
<li><p>The signal after sampling is $x_p(t)=x(t)p(t)=x(t)\sum^{+\infty}_{n=-\infty}\delta(t-nT)=\sum^{+\infty}_{n=-\infty}x(nT)\delta(t-nT) $.<br> $P(\omega)=\frac{2\pi}{T}\sum^{+\infty}_{k=-\infty}\delta(\omega-k\frac{2\pi}{T}) $, and $X_p(\omega)=\frac{1}{2\pi}[X(\omega)\ast P(\omega)]=\frac{1}{T}\sum^{+\infty}_{k=-\infty}X(\omega-k\frac{2\pi}{T}) $. </p>
</li>
</ol>
<h2 id="Reconstruct-signal"><a href="#Reconstruct-signal" class="headerlink" title="Reconstruct signal"></a>Reconstruct signal</h2><ol>
<li>The sampling signal is $x_p(t)=\sum^{+\infty}_{n=-\infty}x(nT)\delta(t-nT) $, which can be seen as the linear combination of $\delta(t-nT)$ with coefficients being $x(nT)$.<br>If $h(t)$ is the filter impulse response, then the reconstructed signal should be $x_r(t)=x_p(t)\ast h(t)=\sum^{+\infty}_{n=-\infty}x(nT)h(t-nT) $. For an ideal lowpass filter with cutoff frequency $\omega_c$, $h(t)=T\frac{\omega_c}{\pi}sinc(\frac{\omega_ct}{\pi})=T\frac{\omega_c}{\pi}\frac{sin(\omega_ct)}{\omega_ct} $<br>Hence the reconstructed signal is linear combination of $h(t-nT)$ with coefficients being $x(nT)$</li>
<li>Zero-order hold: held the sample value until the next sampling to form a staircase curve. Its impulse response is $h(t)=\left\{\begin{matrix}1&amp;0&lt;t&lt;T\\0&amp;otherwise \end{matrix} \right.$</li>
<li>First-order hold: fit an interpolated curve between two sample values, which is a straight line. Its impulse response is a triangular signal with height of $1$ and bottom in $[-T,T]$. </li>
</ol>
<h2 id="Conversion-between-continuous-time-and-discrete-time"><a href="#Conversion-between-continuous-time-and-discrete-time" class="headerlink" title="Conversion between continuous-time and discrete-time"></a>Conversion between continuous-time and discrete-time</h2><ol>
<li><p>After sampling, we acquire a sampled signal of impulse train. But that is still not a discrete-time signal, and a conversion of impulse train to discrete-time sequence is needed. </p>
</li>
<li><p>The sampled signal is $x_p(t)=\sum^{+\infty}_{n=-\infty}x(nT)\delta(t-nT) $, and its Fourier transform is $X_p(t)=\sum^{+\infty}_{n=-\infty}x(nT)e^{-j\omega nT} $.<br>If we want the discrete-time signal to be $x[n]=x(nT)$, then its Fourier transform is $X(\Omega)=\sum^{+\infty}_{n=-\infty}x[n]e^{-j\Omega n} $. </p>
</li>
<li><p>Compare the two Fourier transform equation, we know that if $\Omega=\omega T$, then $X_p(t)=X(\Omega)$. Thus, we have $X(\Omega)=X(\omega)|_{\omega=\Omega/ T}=X(\Omega/T)$. </p>
</li>
<li><p>In the time domain, this step is only relabelling the impulses to discrete-time sequence, namely dividing the time-axis by $T$.<br>In the frequency domain, sampling will replicate the original frequency and this step will multiply the frequency-axis by $T$. </p>
</li>
<li><p>If we want to convert from discrete-time to continuous-time, we only need to undo all the operations aforementioned.<br>In the frequency domain, first divide the frequency-axis by $T$, then use a lowpass filter to remove replicated frequency. </p>
</li>
<li><p>Even the discrete-time filter cutoff is fixed, changing the sampling frequency will still change the cutoff frequency of the equivalent continuous-time filter. </p>
</li>
</ol>
<h1 id="Discrete-time-sampling"><a href="#Discrete-time-sampling" class="headerlink" title="Discrete-time sampling"></a>Discrete-time sampling</h1><ol>
<li>The sampling impulse sequence is $p[n]=\sum^{+\infty}_{k=-\infty}\delta(n-kN)$ and its Fourier transform is $P(\Omega)=\frac{2\pi}{N}\sum^{+\infty}_{k=-\infty}\delta(\Omega-k\frac{2\pi}{N})$.<br>The sampled signal is $x_p[n]=x[n]p[n]$, and its Fourier transform is $X_p(\Omega)=\frac1{2\pi}\int_{2\pi}P(\theta)X(\Omega-\theta)d\theta=\frac1N\sum^{N-1}_{k=0}X(\Omega-k\frac{2\pi}{N})$</li>
<li>The sampling theorem also applies to discrete-time sampling. In the aformentioned equations, the sampling frequency is $\Omega_s=\frac{2\pi}{N}$. </li>
<li>The discrete-time sample will set some values to zero. And storing those zeros is inefficient since we can easily insert them back given sampling frequency.<br>A decimated sequence removes those zeros and only keeps the values associated with the original sequence. Decimating is to pick out every $n^{th}$ sample and end up with a collaped sequence. </li>
<li>Define the decimated sequence $x_d[n]=x[nN]=x_p[nN]$. Substitute $n=mN$ into the Fourier transform $X_p(\Omega)=\sum^{+\infty}_{n=-\infty}x_p[n]e^{-j\Omega n}=\sum^{+\infty}_{m=-\infty}x_p[mN]e^{-j\Omega mN}$. Given the Fourier transform of $x_d[n]$ is $X_d(\Omega)=\sum^{+\infty}_{m=-\infty}x_d[m]e^{-j\Omega m}$, compare the two equations to get that $X_d(\Omega)=X_p(\Omega/N)$.<br>So, in frequency domain, decimating will scale the frequency-axis by $N$, namely multiply the frequency-axis by $N$. </li>
<li>Downsampling is to decrease the sampling rate (sampling frequency). In time domain, t simply removes some values from the sampled sequence. In frequency domain, it<br>Upsampling is to recovering a signal after it has been decimated. To do so, must convert the decimated sequency to sampled sequence, and then use a lowpass filter to acquire the signal before decimating. </li>
<li>If we want to decrease the sampling rate by an integer $k$, namely $T_2=2T_1$ we need to downsample and decimate by $1:k$. If we want to increate the sampling rate by an integer $k$, namely $T_2=\frac12T_1$, we need to upsample and interpolate by $k:1$.<br>If we want to change the sampling rate by $T_2=\frac{P}QT_1$, we need to upsample and interpolate by $Q:1$, then downsample and decimate by $1:P$. </li>
</ol>
<h1 id="Frequency-domain-sampling"><a href="#Frequency-domain-sampling" class="headerlink" title="Frequency domain sampling"></a>Frequency domain sampling</h1><ol>
<li>Similar to time domain sampling, frequency domain sampling also multiplies the frequency function $X(\omega)$ by a sample function $P(\omega)=\sum^{+\infty}_{k=-\infty}\delta(\omega-k\omega_0)$. The sampled frequency function is $\tilde{X}(\omega)=X(\omega)P(\omega)=\sum^{+\infty}_{k=-\infty}X(k\omega_0)\delta(\omega-k\omega_0)$. </li>
<li>In frequency domain, $\tilde{X}(\omega)$ is a train of impulse response.<br>In time domain, it replicates $x(t)$ with period of $\frac{2\pi}{\omega_0}$ and scale by $\frac{1}{\omega_0}$. </li>
<li>To recover the original signal, we just multiply $\tilde{x}(t)$ with a time window to retain only one period. </li>
<li>The aformentioned operations also apply to discrete-time signals. </li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2022/06/25/07-Modulation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2022/06/25/07-Modulation/" class="post-title-link" itemprop="url">07. Modulation</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-06-25 14:56:13" itemprop="dateCreated datePublished" datetime="2022-06-25T14:56:13+08:00">2022-06-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-06-28 11:22:18" itemprop="dateModified" datetime="2022-06-28T11:22:18+08:00">2022-06-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index">
                    <span itemprop="name">计算机科学与技术</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F-MIT-6-007/" itemprop="url" rel="index">
                    <span itemprop="name">信号与系统 (MIT 6.007)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Continuous-time-modulation"><a href="#Continuous-time-modulation" class="headerlink" title="Continuous-time modulation"></a>Continuous-time modulation</h1><h2 id="Synchronization"><a href="#Synchronization" class="headerlink" title="Synchronization"></a>Synchronization</h2><ol>
<li>In the modulation property, $x(t)c(t)$ and $\frac{1}{2\pi}[X(\omega)\ast C(\Omega)]$ are a Fourier transform pair. We call $x(t)$ the modulating signal, $c(t)$ the carrier, and $y(t)=x(t)c(t)$ the modulated signal. </li>
<li>The complex exponential carrier is $c(t)=e^{j(\omega_ct+\theta_c)}$. It will shift $X(\omega)$ by $\omega_c$. If we want to recover $x(t)$ from $y(t)$, we only need to divide $y(t)$ by $c(t)$ or multiply $y(t)$ with $e^{-j(\omega_ct+\theta_c)}$. </li>
<li>One practical usage of complex exponential carrier is to combine with filters. We can build a filter with fixed center frequency. Modulate the input signal before passing through the filter to shift the desired frequency to the passband, and demodulate the output of filter to recover the original frequency position.<br>Building a fixed center frequency filter and modulators is easier and cheaper than building a bandpass filter with varying center frequency. </li>
<li>The sinusoidal carrier is $c(t)=cos(\omega_ct+\theta_c)$. $c(t)=cos(\omega_ct+\theta_c)=\frac12e^{j(\omega_ct+\theta)}+\frac12e^{-j(\omega_ct+\theta_c)}$, so we can know that this carrier will replicate $X(\omega)$, and shift one by $\omega_c$ and the other by $-\omega_c$.<br>To demodulate, we need to modulate the output with the same carrier again and pass through a filter with scaling. </li>
<li>Multiplexing: Use modulation to shift spectra to different frequency band without overlapping, and then add them together.<br>Demultiplexing: When we have received the multiplexing signal and want to separate the one signal we need, we can demultiplex with bandpass filter, and demodulate according to the carrier. </li>
<li>The aformentioned modulations are all synchronization modultaion, namely the modulator and demodulator have a synchronization in both frequency and phase. </li>
</ol>
<h2 id="Asynchronization"><a href="#Asynchronization" class="headerlink" title="Asynchronization"></a>Asynchronization</h2><ol>
<li><p>However, building a synchronization demodulator can be expensive, and we would want a cheap asynchronization demodulator. </p>
</li>
<li><p>Normally, we can achieve a pretty good effect with a simple diode RC circuit. </p>
</li>
<li><p>Assume that the envelope of signal $y(t)$ is the desired demodulated signal $x(t)$. The demodulator tends to generate a full-wave rectified version of the signal (rectifies the negative component of input).<br>The simple solution is to make sure that $x(t)$ is always positive, namely we add a large enough constant $A$ to $x(t)$, so that $x(t)+A$ is always positive.<br>So in the modulation part, we need to add a $Ac(t)$ to $x(t)c(t)$ to form the modulated signal. The carrier is injected to the modulated signal. </p>
</li>
<li><p>With larger $A$, the demodulated signal tends to be flat, and easy to track it with circuit.<br>Yet, with larger $A$, the part of injection of carrier is larger, and it is not an information carrying part of the signal. So it represents some inefficiency in transmission.<br>The injection of a carrier is simply to make the demodulation for an asynchronous demodulator to make the demodulation easier. So the tradeoff is that if the transmission is simpler, then the demodulator is more complicated, and if the demodulator is more simpler, the transmission is more inefficient and takes more energy. </p>
</li>
<li><p>Another issue is that after modulated by a sinusoidal carrier, the frequency signal is replicated, and we might want to remove the redundence.<br>The solution is that we can use a highpass filter to obtain a single-sideband signal which only the upper sidebands are retained or use a lowpass filter to obtain a single-sideband signal which only the lower sidebands are retained. </p>
</li>
</ol>
<h1 id="Discrete-Time-Modulation"><a href="#Discrete-Time-Modulation" class="headerlink" title="Discrete-Time Modulation"></a>Discrete-Time Modulation</h1><ol>
<li><p>Complex exponential carrier is $c[n]=e^{j(\Omega_cn+\theta_c)}$. It will shift the frequency by $\Omega_c$. </p>
</li>
<li><p>Simusoidal carrier is $c[n]=cos \Omega_cn=\frac12e^{j\Omega_cn}+\frac12e^{-j\Omega_cn}$. It will replicate the frequency, and shift one by $\Omega_c$ another one by $-\Omega_c$. </p>
</li>
<li><p>The demodulation of simusoidal carrier is to modulate the output with the same carrier again and pass through a filter with scaling. </p>
</li>
<li><p>Another common used carrier is $c[n]=(-1)^n=e^{j\pi n}$. It will shift the frequency by $\pi$, which actually interchanges the low frequency and the high frequency.<br>Its demodulator is itself. We can use it to implement a highpass filter with a lowpass filter. Before the filter, we modulate the signal with $c[n]$, and demodulate it after the filter. </p>
</li>
<li><p>Pulse carrier of continuous-time is $p(t)$ has non-zero values of width $\Delta$ in every period $T$. In discrete-time case, $p[n]$ has non-zero values of width $M$ in every period $N$.<br>In time domain perspective, the output only keep the part where $p(t)$ or $p[n]$ is non-zero. In frequency domain perspective, the frequency is replicated and scaled.<br>If the original frequency is band limited, to demodulate a pulse carrier, we only need to pass the signal through a low frequency filter and scale it. </p>
</li>
<li><p>In time division multiplexing, it is required that the time slopts are not overlapped. Every $\Delta$ or $M$ is a time slot, and we can transmit different signal with different pulse carrier.<br>Luckily, the bandwidth of frequency after modulated is not limited by $\Delta$. Hence, theoretically, we can set $\Delta$ as small as possible to maximum the number of signals we can transmit at the same time.<br>However, the height in the frequency domain is proportional to $\Delta$. So with smaller $\Delta$, the less energy there is and noise problem might be worse. </p>
</li>
<li><p>To solve the problem, we can fix the area of each time slot, namly that each time slot has width of $\Delta$ and height of $\frac1\Delta$. As $\Delta\to 0$, $p(t)$ becomes an impulse train. </p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2022/06/24/06-Filtering/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2022/06/24/06-Filtering/" class="post-title-link" itemprop="url">06. Filtering</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-06-24 18:29:49" itemprop="dateCreated datePublished" datetime="2022-06-24T18:29:49+08:00">2022-06-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-06-25 15:03:35" itemprop="dateModified" datetime="2022-06-25T15:03:35+08:00">2022-06-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index">
                    <span itemprop="name">计算机科学与技术</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F-MIT-6-007/" itemprop="url" rel="index">
                    <span itemprop="name">信号与系统 (MIT 6.007)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ol>
<li><p>According to the convolution property, if $H(\omega)$ or $H(\Omega)$ is nonzero, that frequency is passed to the output. If $H(\omega)$ or $H(\Omega)$ is zero, that frequency will not contribute to the output.<br>Then band of nonzero part is called passband, while the band of zero part is called stopband. </p>
</li>
<li><p>For continuous-times case, if the passband is around zero, that filter is a lowpass filter. If the stopband is around zero, that filter is a highpass filter. Combine a lowpass filter and a highpass filter to get a bandpass filter which passes the frequency in the middle. </p>
</li>
<li><p>For discrete-time case, if the passband is around $2\pi m$, that filter is a lowpass filter. If the passband is around $(2m+1)\pi$, that filter is a highpass filter. Also combine a lowpass filter and a highpass filter can get a bandpass filter whose pass band is between $2m\pi$ and $(2m+1)\pi$. </p>
</li>
<li><p>The amplitudes of ideal filters are either 1 or 0.<br>Their impulse response and the step response both have an oscillation which might be undesirable.<br>Furthermore, their impulse responses are even, and have tails that go off to $+\infty$ and $-\infty$, namely the ideal filters are non-causal. Thus we cannot build an ideal filter that restrictly operates on real time. </p>
</li>
<li><p>In a non-ideal filter, instead of a very rapid transition from passband to stopband, there would be a more gradual transition with a passband cutoff frequency and a stopband cutoff frequency.<br>Also instead of having an exactly flat characteristic in the stopband and passband, a certain amount of ripple is allowed.<br>Normally, the sharper you attempt to make the cutoff, the more expensive the filter becomes. </p>
</li>
<li><p>Non-recursive (moving average) filter: $y[n]=\frac{1}{N+M+1}\sum^{M}_{k=-N}x[n-k]$<br>Recursive filter: $\sum^N_{k=0}a_ky[n-k]=\sum^M_{k=0}b_kx[n-k]$</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2022/06/23/05-Discrete-Time-Fourier-Analysis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2022/06/23/05-Discrete-Time-Fourier-Analysis/" class="post-title-link" itemprop="url">05. Discrete-Time Fourier Analysis</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-06-23 18:01:02" itemprop="dateCreated datePublished" datetime="2022-06-23T18:01:02+08:00">2022-06-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-07-11 18:14:31" itemprop="dateModified" datetime="2022-07-11T18:14:31+08:00">2022-07-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index">
                    <span itemprop="name">计算机科学与技术</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F-MIT-6-007/" itemprop="url" rel="index">
                    <span itemprop="name">信号与系统 (MIT 6.007)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Fourier-series"><a href="#Fourier-series" class="headerlink" title="Fourier series"></a>Fourier series</h1><ol>
<li>As the continuous-time case, we choose the basic signal to be $\phi_k[n]=e^{j\Omega_kn}$. From convolution, we know that its response is $e^{j\Omega_kn}\sum^{+\infty}_{r=-\infty}h[r]e^{-j\Omega_kr}=H(\Omega_k)e^{j\Omega_kn}$</li>
<li>If $x[n]$ is periodic with period ans fundamental frequency being $N$ and $\Omega_0=\frac{2\pi}{N}$, then we try to represent $x[n]=\sum_ka_ke^{jk\Omega_0n}$. Give that, in discrete-time complex exponential, $e^{jk\Omega_0n}=e^{j(k+N)\Omega_0n}$, we don’t need $k$ from $-\infty$ to $+\infty$. Instead, we only want $k$ in a period range $N$, like $[0, N-1]$.<br>Thus, the synthesis equation is $x[n]=\sum_{k=\lt N\gt}a_ke^{j(k+N)\Omega_0n}$</li>
<li>To solve $a_k$, we can actually see it as $N$ equations with $N$ unknowns. And finally the analysis equation is $a_k=\frac1N\sum_{\lt N\gt}x[n]e^{jk\Omega_0n}$</li>
<li>We need infinity number of coefficients in continuous-time, while only finite number is required in discrete-time. </li>
<li>$x[n]$ and $e^{jk\Omega_0n}$ are both periodic in $n$, like in continuous-time.<br>$e^{jk\Omega_0n}$ and $a_k$ are both periodic in $k$, while continuous-time is not the case. </li>
<li>In discrete-time, the Fourier serise will always convergent. However, in continuous-time, this is conditional. </li>
</ol>
<h1 id="Fourier-transform"><a href="#Fourier-transform" class="headerlink" title="Fourier transform"></a>Fourier transform</h1><ol>
<li>For an aperiodic singal $x[n]$, we can construct a periodic signal $\tilde{x}[n]$ with period being $N$ and one period being $x[n]$.<br> The Fouier series of $\tilde{x}[n]=\sum_{\lt N\gt}\frac{1}{2\pi}X(k\Omega_0)e^{jk\Omega_0n}\Omega_0$ and $X(k\Omega_0)=Na_k=\sum^{N/2}_{k=-N/2}\tilde{x}[n]e^{-jk\Omega_0n}$. </li>
<li>As $N\to\infty$, $\Omega_0\to0$ and $\tilde{x}[n]\to x[n]$, the synthesis equation is $x[n]=\frac{1}{2\pi}\int_{2\pi}X(\Omega)e^{j\Omega n}d\Omega$ and the analysis equation is $X(\Omega)=\sum^{+\infty}_{k=-\infty}x[n]e^{-j\Omega n}$<br>$x[n]$ and $X(\Omega)$ are a Fourier transform pair. </li>
<li>The discrete-time Fourier transform lacks the duality in continuous-time since $x[n]$ is a discrete-time signal while $X(\Omega)$ is a continous-frequency signal. </li>
<li>If $\tilde{x}[n]$ is periodic and $x[n]$ represents a period, then the Fourier series coefficients of $\tilde{x}[n]=\frac{1}{N}\times$ samples of Fourier transform of $x[n]$, namely $a_k=\frac1NX(\Omega)|_{\Omega=\frac{2\pi k}{N}}$. </li>
<li>If $\tilde{x}[n]$ is periodic, the Fourier transform of $\tilde{x}[n]$ is defined as impulse train, $\tilde{X}(\Omega)=\sum^{+\infty}_{k=-\infty}2\pi a_k\delta(\Omega-k\Omega_0)$</li>
</ol>
<h1 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h1><ol>
<li>Periodic: $X(\Omega)=X(\Omega+2\pi m)$</li>
<li>Symmetry:<br>If $x[n]$ is real, then $X(-\Omega)=X^*(\Omega)$<br>The real part of $X(\Omega)$ and its amplitude is an even function, while the imaginary part $X(\Omega)$ and its phase is an odd function. </li>
<li>Time shifting in time function corresponds in phase change in Fourier transform, $x[n-n_0]$ and $e^{-j\Omega n_0}X(\Omega)$ are a Fourier transform pair. </li>
<li>Phase shifting in time function corresponds in frequency shifting in Fourier transform, $e^{j\Omega_0n}x[n]$ and $X(\Omega-\Omega_0)$ are a Fourier transform pair. </li>
<li>Linearity: $ax_1[n]+bx_2[n]$ and $aX_1[n]+bX_2[n]$ are a Fourier transform pair. </li>
<li>Parseval’s relation: $\sum^{+\infty}_{k=-\infty}|x[n]|^2=\frac1{2\pi}\int_{2\pi}|X(\Omega)|^2d\Omega $</li>
<li>Convolution: $h[n]\ast x[n]$ and $H(\Omega)X(\Omega)$ are a Fourier transform pair. $H(\Omega)$ is the frequency response and the Fourier transform of impulse response $h[n]$<br>If the input signal is $e^{j\Omega_0n}$, the output should be $e^{j\Omega_0n}H(\Omega_0)$</li>
<li>The lowpass filter $H(\Omega)$ should have nonzero values not only around $0$, but also around $2\pi m$.<br>The highpass filter $H(\Omega)$ should have nonzero values around every $(2k+1)\pi$.<br>The frequency of input is in $[-\pi, \pi]$</li>
<li>Modulation: $x_1[n]x_2[n]$ and $\frac{1}{2\pi}\int_{2\pi}X_1(\theta)X_2(\Omega-\theta)d\theta$</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2022/06/22/04-Continuous-Time-Fourier-Analysis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2022/06/22/04-Continuous-Time-Fourier-Analysis/" class="post-title-link" itemprop="url">04. Continuous-Time Fourier Analysis</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-06-22 13:40:58" itemprop="dateCreated datePublished" datetime="2022-06-22T13:40:58+08:00">2022-06-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-07-11 19:18:34" itemprop="dateModified" datetime="2022-07-11T19:18:34+08:00">2022-07-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index">
                    <span itemprop="name">计算机科学与技术</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F-MIT-6-007/" itemprop="url" rel="index">
                    <span itemprop="name">信号与系统 (MIT 6.007)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Fourier-analysis"><a href="#Fourier-analysis" class="headerlink" title="Fourier analysis"></a>Fourier analysis</h1><ol>
<li>In Fourier analysis, we decompose signals into basic signals of complex exponentials.<br>In continuous-time case, $s_k=j\omega_k$, which is pure imaginary, And $\phi_k(t)=e^{s_kt}=e^{j\omega_kt}$.<br>In discrete-time case, $|z_k|=1$, and $\phi_k[n]=e^{j\Omega_kt}$</li>
<li>If we represent the response of $\phi_k(t)$ as the convolution integral, $\int^{+\infty}_{-\infty}h(t)e^{j\omega_k(t-\tau)}d\tau=e^{j\omega_kt}\int^{+\infty}_{-\infty}h(t)e^{-j\omega_k\tau}d\tau=H(\omega_k)e^{j\omega_kt} $ .<br>Namely the system is $e^{j\omega_kt}\to H(\omega_k)e^{j\omega_kt}$. This means the reponse is the same signal scaled by $H(\omega_k)=\int^{+\infty}_{-\infty}h(t)e^{-j\omega_k\tau}d\tau$. $e^{j\omega_kt}$ is called the eigenfunction while $H(\omega_k)$ is the eigenvalue. </li>
<li>When $x(t)$ is periodic, we can decompose it into Fourier series. When $x(t)$ is aperiodic, we can still perform Fourier transform to represent it through Fourier seirier. </li>
</ol>
<h1 id="Fourier-Series"><a href="#Fourier-Series" class="headerlink" title="Fourier Series"></a>Fourier Series</h1><ol>
<li>$e^{j\omega_0t}$ with $T_0=\frac{2\pi}{\omega_0}$ and $e^{jk\omega_0t}$ with $T_0=\frac{2\pi}{k\omega_0}$ are harmonically related exponentials. </li>
<li>For a periodic signal $x(t)$ with period being $T_0$, we can represent it  by linear combinations of harmonically related exponentials $x(t)=\displaystyle\sum^{+\infty}_{k=-\infty}a_ke^{jk\omega_0t} $, which is called the synthesis equation with $\omega_0=\frac{2\pi}{T_0}$ and $a_k$ are complex coefficient. </li>
<li>Or we can write it as the trigonometric form which expands $a_k=A_ke^{j\theta_k}$ in the polor form or $a_k=B_k+jC_k$ in the rectangle form, and $e^{jk\omega_0t}=cos(k\omega_0t)+jsin(k\omega_0t) $. $x(t)=a_0+2\displaystyle\sum^{+\infty}_{k=-\infty}A_kcos(k\omega_0t+\theta_k) $ or $x(t)=a_0+2\displaystyle\sum^{+\infty}_{k=-\infty}[B_kcos(k\omega_0t)-C_ksin(k\omega_0t)] $</li>
<li>$\int_{T_0}e^{jm\omega_0t}dt=\int_{T_0}cos(m\omega_0t)+j\int_{T_0}sin(m\omega_0t)dt=\left\{\begin{matrix}0+0&amp;m≠0\\T_0+0&amp;m=0 \end{matrix}\right. $<br>To calculate $a_k$, $\int_{T_0}x(t)e^{-jn\omega_0t}dt=\int_{T_0}e^{-n\omega_0t}\sum^{+\infty}_{k=-\infty}a_ke^{jk\omega_0t}=\sum^{+\infty}_{k=-\infty}a_k\int_{T_0}e^{j(k-n)\omega_0t}dt=a_nT_0$. Thus the analysis equation $ a_n=\frac1{T_0}\int_{T_0}x(t)e^{-jn\omega_0t}dt $</li>
<li>The coefficients of an odd signal are odd harmonic (all even indexed terms are zero). And odd signals can be represented by sums of $sin$.<br>The coefficients of an even signal are even harmonic (all odd indexed terms are zero). And even signals can be represented by sums of cos. </li>
<li>It is the low-frequency terms that represent the broad time behavior, and it is the high-frequency terms that areused to build up the sharp transitions in the time domain. </li>
<li>We define the partial sum as $x_N(t)=\sum^N_{k=-N}a_ke^{jk\omega_0t}$ and the error function $e_N(t)=x(t)-x_N(t)$.<br>If $\int_{T_0}|x(t)|^2dt&lt;\infty $, then $\int_{T_0}|e_N(t)|^2dt\to0$ as $N\to\infty$.<br>Dirichlet conditions: If $\int_{T_0}|x(t)|dt&lt;\infty$ and $x(t)$ has limited maximum or minimum point at a period, then $e_N(T)\to0$ as $N\to0$ except at discontinuous. </li>
</ol>
<h1 id="Fourier-transform"><a href="#Fourier-transform" class="headerlink" title="Fourier transform"></a>Fourier transform</h1><ol>
<li>For an aperiodic signal $x(t)$, we can take it and repeat it at multiples of some period $T_0$ to get $\tilde{x}(t)$. As $T_0\to\infty$, $\tilde{x}(t)\to x(t)$.<br>Now, we use Fourier series to represent $\tilde{x}(t)$, then let $T\to\infty$ to represent $x(t)$</li>
<li>The Fourier series of $\tilde{x}(t)$ is $a_k=\frac{1}{T_0}\int^{T_0/2}_{-T_0/2}\tilde{x}(t)e^{-jk\omega_0t}dt$. As $T_0\to\infty$, we can modify the integral to $a_k=\frac{1}{T_0}\int^{+\infty}_{-\infty}x(t)e^{-jk\omega_0t}dt$. If we define $X(\omega)=\int^{+\infty}_{-\infty}x(t)e^{-j\omega t}dt$, then $T_0a_k=X(\omega)|_{\omega=k\omega_0}$. Namely $X(\omega)$ is the envelope of $T_0a_k$. And we can see $a_k$ as samples on $\frac{1}{T_0}X(\omega)$<br>$\tilde{x}(t)=\sum^{+\infty}_{k=-\infty}\frac{1}{T_0}X(k\omega_0)e^{jk\omega_0t}=\frac{1}{2\pi}\sum^{+\infty}_{k=-\infty}X(k\omega_0)e^{jk\omega_0t}\omega_0 $.<br>As $T_0\to\infty$, $x(t)=\frac{1}{2\pi}\int^{+\infty}_{-\infty}X(\omega)e^{j\omega t}\omega d\omega $</li>
<li>Define the envelope $X(\omega)=\int^{+\infty}_{-\infty}x(t)e^{-j\omega t}dt$ as the Fourier transform of $x(t)$ or the analysis equation. $x(t)$ and $X(\omega)$ is a Fourier transform pair.<br>Define $x(t)=\frac{1}{2\pi}\int^{+\infty}_{-\infty}X(\omega)e^{j\omega t}\omega d\omega$ as the inverse Fourier transform or the synthesis equation. </li>
<li>To apply Fourier tranform to a periodic signal $\tilde{x}(t)$, we can define its Fourer tranform as $\tilde{X}(t)=\sum^{+\infty}_{k=-\infty}2\pi a_k\delta(\omega-k\omega_0) $, where $a_k$ are the Fourier series coefficients.<br>Substitude to the systhesis equation of Fourier transform, $\tilde{x}(t)=\frac{1}{2\pi}\int^{+\infty}_{-\infty}\tilde{X}(t)e^{j\omega t}d\omega=\frac{1}{2\pi}\sum^{+\infty}_{k=-\infty}2\pi a_k\int^{+\infty}_{-\infty}\delta(\omega-k\omega_0)e^{j\omega t}d\omega=\sum^{+\infty}_{k=-\infty}a_ke^{-jk\omega_0} $</li>
<li>When $x(t)$ is aperiodic, we can construct periodic signal $\tilde{x}(t)$ for<br>which one period is $x(t)$. As the period of $\tilde{x}(t)$ increases, $\tilde{x}(t)\to x(t)$, and Fourier series of $\tilde{x}(t)\to$ Fourier transform of $x(t)$.<br>If $\tilde{x}(t)$ is periodic, $x(t)$ represents one period, Fourier series coefficients of $x(t)=\frac{1}{T_0}\times$ samples of Fourier transform of $x(t)$<br>If $\tilde{x}(t)$ is periodic, Fourier transform of $\tilde{x}(t)$ defined as impulse train $\tilde{X}(t)$. </li>
</ol>
<h1 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h1><ol>
<li>Symmetry:<br>$x(t)$ is real $\Rightarrow$ $X(-\omega)=X^*(\omega)$<br>The real part of $X(\omega)$ is an even function, $Re\{X(-\omega)\}=Re\{X(\omega)\}$<br>The amplitude of $X(\omega)$ is an even function, $|X(-\omega)|=|X(\omega)|$<br>The imaginary part of $X(\omega)$ is an odd function, $Im\{X(-\omega)\}=-Im\{X(\omega)\}$.<br>The phase of $X(\omega)$ is an odd function. </li>
<li>The linear scaling at time results in the inverse scaling at frequency. Namely, $x(at)$ is paired with $\frac{1}{|a|}X(\frac{\omega}{a})$</li>
<li>Duality: If $x(t)$ and $X(\omega)$ are a Fourier transform pair, the Fourier transform of $X(t)$ is $2\pi x(-\omega)$</li>
<li>Parseval’s relation:<br>The energe of an aperiodic time signal is proportional to its Fourier transform, $\int^{+\infty}_{-\infty}|x(t)|^2dt=\frac{1}{2\pi}\int^{+\infty}_{-\infty}|X(\omega)|^2d\omega $<br>The energe of a periodic time signal in a period is proportional to its Fourier series, $\frac{1}{T_0}\int_{T_0}|\tilde{x}(t)|^2dt=\sum^{+\infty}_{k=-\infty}|a_k|^2$</li>
<li>Time shifting: $x(t-t_0)$ and $e^{-j\omega t_0}X(\omega)$ are a Fourier transform pair. A time shift correspond to a linear change in phase and frequency. </li>
<li>Differentiation: $\frac{dx(t)}{dt}$ and $j\omega X(\omega)$ are a Fourier transform pair. A differentiation correspond to a linear change on the amplitude.<br>Integration: $\int^t_{-\infty}x(\tau)d\tau$ and $\frac{1}{j\omega}X(\omega)+\pi X(0)\delta(\omega)$</li>
<li>Linearity: $ax_1(t)+bx_2(t)$ and $aX_1(t)+bX_2(t)$ are a Fourier transform pair. The Fourier transfm of a linear combination is the linear combination of their Fourier transform. </li>
<li>Convolution property: The Fourier transform of $x(t)\ast h(t)$ is $H(\omega)X(\omega)$, where the frequency response $H(\omega)$ is the Fourier transform of impulse response $h(t)$.<br>The idea lowpass filter only keep the signals with frequency between $-\omega_0$ and $\omega_0$. Thus its frequency response is $H(\omega)=\left\{\begin{matrix}1&amp; -\omega_0≤\omega≤\omega_0\\0&amp;otherwise \end{matrix}\right.$<br>From the differentiation property, we can know that the frequency response is $H(\omega)=j\omega$. It amplifies high frequencies and attenuates low frequencies. </li>
<li>Modulation property: The Fourier transform of $s(t)p(t)$ is $\frac{1}{2\pi}[S(\omega)\ast P(\omega)]$</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2022/06/21/03-Systems-Represented-by-Differential-Equations/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2022/06/21/03-Systems-Represented-by-Differential-Equations/" class="post-title-link" itemprop="url">03. Systems Represented by Differential Equations</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-06-21 11:50:42 / Modified: 19:49:21" itemprop="dateCreated datePublished" datetime="2022-06-21T11:50:42+08:00">2022-06-21</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index">
                    <span itemprop="name">计算机科学与技术</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F-MIT-6-007/" itemprop="url" rel="index">
                    <span itemprop="name">信号与系统 (MIT 6.007)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Operational-definition​"><a href="#Operational-definition​" class="headerlink" title="Operational definition​"></a>Operational definition​</h1><ol>
<li><p>For an identity system, its impulse response is $h(t)=\delta(t)$ or $h[n]=\delta[n] $. If we cascade two identity system, the overall system is still an identity system, and its impulse response is $\delta(t)\ast\delta(t)=\delta(t) $ or $\delta[n]\ast\delta[n]=\delta[n] $. </p>
</li>
<li><p>Operational definition: Focus not on what the impulse is , but to what the impulse does under the operation of convolution. </p>
</li>
<li><p>For a differentiator, its impulse response is $u_1(t)=\displaystyle\frac{d}{dt}\delta(t)$. What is $u_1(t)$ is difficult to find out, but we know that $x(t)\ast u_1(t)=\displaystyle\frac{d}{dt}x(t)$.<br>If we cascade two differentiator together, the impulse response is denoted $u_2(t)=u_1(t)\ast u_1(t) $. What $u_2(t) $ does is that $x(t)\ast u_2(t)=\displaystyle\frac{d^2}{dt^2}x(t) $.<br>If we cascade $k$ differentiator together, the impulse response is $u_k(t)=u_1(t)\ast u_1(t)\cdots $, and $x(t)\ast u_k(t)=\displaystyle\frac{d^k}{dt^k}x(t)$. </p>
</li>
<li><p>For an integrator, its impulse response is $u_{-1}(t)=u(t) $.<br>if we cascade two integrator, its impulse response is $u_{-2}(t)=$ unit ramp.<br>$x(t)\ast u_{-m}(t)=$ $m^{th}$ running  integral. </p>
</li>
<li><p>For $u_k(t)$, where $k$ can be either positive or negative:<br>$u_0(t)=\delta(t) $, $u_{-1}(t)=u(t)$.<br>$u_k(t)\ast u_l(t)=u_{k+l}(t) $.  </p>
</li>
</ol>
<h1 id="Differential-equation"><a href="#Differential-equation" class="headerlink" title="Differential equation"></a>Differential equation</h1><ol>
<li>$N^{th}$ order Linear constant-coefficient differential equation: $\displaystyle\sum^N_{k=0}a_k\frac{d^ky(t)}{dt^k}=\sum^N_{k=0}b_k\frac{d^kx(t)}{dt^k}$.<br>The “linear” here only means linear combination. There is no guarentee that the system is linear. </li>
<li>$\displaystyle\sum^N_{k=0}a_k\frac{d^ky_h(t)}{dt^k}=0$ is the homogeneous equation, and its solution $y_h(t)$ is the homogeneous solution.<br>For any $y_s(t)$ being the solution of the differential equation, $y_s(t)+y_h(t)$ is also a solution. </li>
<li>Guess $y_h(t)=Ae^{st}$. Substitute it to the homogeneous equation to get $\displaystyle\sum^N_{k=0}a_kAs^ke^{st}=0\Rightarrow\sum^N_{k=0}a_ks^k=0$. This equation has $N$ complex roots, and thus $y_h(t)=\displaystyle\sum^N_{k=0}A_ke^{s_kt}$ with $A_i$ being unspecified coeffecients. </li>
<li>The solution of the differential equation is $y(t)=y_h(t)+y_p(t)$ where $y_p(t)$ is a particular solution of the equation.<br>With $N$ auxiliary conditions about $y(t), \frac{dy(t)}{dt}, \cdots,\frac{d^Ny(t)}{dt^N}$ at $t=t_0$, we can solve all $A_i$ in $y(t)$. </li>
<li>A system being linear $\Leftrightarrow$ all auxiliary conditions must be 0.<br>An LTI system being causal $\Leftrightarrow$ initial rest. </li>
</ol>
<h1 id="Difference-equation"><a href="#Difference-equation" class="headerlink" title="Difference equation"></a>Difference equation</h1><ol>
<li><p>$N^{th}$ order Linear constant-coefficient difference equation: $\displaystyle\sum^N_{k=0}a_ky[n-k]=\sum^N_{k=0}b_kx[n-k]$. </p>
</li>
<li><p>The homogeneous equation is $\displaystyle\sum^N_{k=0}a_ky[n-k]=0$, and its solution is $y_h[n]$.<br>For any $y_s[n]$ being the solution of the difference equation, $y_s[n]+y_h[n]$ is also a solution. </p>
</li>
<li><p>Guess $y_h[n]=Az^n$. Substitute it to the homogeneous equation to get $\displaystyle\sum^N_{k=0}a_kAz^nz^{-k}=0\Rightarrow\sum^N_{k=0}a_kz^{-k}=0$. This equation has $N$ complex roots, and thus $y_h[n]=\displaystyle\sum^N_{k=0}A_kz_k^n$ with $A_i$ being undetermined coeffecients. </p>
</li>
<li><p>The solution is $y[n]=y_h[n]+y_p[n]$.<br>With $N$ auxiliary conditions about $y[n], y[n-1], \cdots,y[n-N+1]$ at $n=n_0$, we can solve all $A_i$ in the solution of differential equation. </p>
</li>
<li><p>A system being linear $\Leftrightarrow$ all auxiliary conditions must be 0.<br>An LTI system being causal $\Leftrightarrow$ initial rest. </p>
</li>
<li><p>From the difference equation, we can have $y[n]=\frac{1}{a_0}\displaystyle(\sum^N_{k=0}b_kx[n-k]-\sum^N_{k=1}a_ky[n-k])$.<br>Thus when the system is causal and LTI, we can calculate $y[n]$ from the first nonzero input $n=n_0$ since we know that all $y[n]$ with $n&lt;n_0$ is zero. </p>
</li>
</ol>
<h1 id="Diagram"><a href="#Diagram" class="headerlink" title="Diagram"></a>Diagram</h1><ol>
<li><p>The diagram of the causal LTI difference equation system is as followed:<br><img src="/img/03-Systems-Represented-by-Differential-Equations-1.png" width="40%"><br>We can see the two sets of delay operation as two cascaded system and swap their position.<br><img src="/img/03-Systems-Represented-by-Differential-Equations-2.png" width="40%"><br>Now, the input of those two sets of delay operation is the same, so we can merge them into only one set.<br><img src="/img/03-Systems-Represented-by-Differential-Equations-3.png" width="40%"></p>
</li>
<li><p>Similar to difference equation, we can have the diagram of the causal LTI differetial equation system as followed (move all terms except $\frac{d^Ny(t)}{dt^N}$ to the left, and integrate $N$ times):<br><img src="/img/03-Systems-Represented-by-Differential-Equations-4.png" width="40%"><br>Swap and merge the integrators to have the followed diagram:<br><img src="/img/03-Systems-Represented-by-Differential-Equations-5.png" width="40%"></p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2022/06/19/08-Snooping-based-Cache-Coherence/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2022/06/19/08-Snooping-based-Cache-Coherence/" class="post-title-link" itemprop="url">08. Snooping-based Cache Coherence</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-06-19 19:30:41" itemprop="dateCreated datePublished" datetime="2022-06-19T19:30:41+08:00">2022-06-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-07-07 17:15:46" itemprop="dateModified" datetime="2022-07-07T17:15:46+08:00">2022-07-07</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index">
                    <span itemprop="name">计算机科学与技术</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-CMU-15-418-Stanford-CS149/" itemprop="url" rel="index">
                    <span itemprop="name">并行计算 (CMU 15-418 / Stanford CS149)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="The-cache-coherence-problem"><a href="#The-cache-coherence-problem" class="headerlink" title="The cache coherence problem"></a>The cache coherence problem</h1><ol>
<li>This problem happens in a shared memory multi-processor system. Reading a value at address X should return the last value written to address X by any processor. </li>
<li>This is a problem created by replicating the data stored at address X in local caches (a hardware implementation detail), and cannot be fixed by adding locks. </li>
<li>Memory coherence problem exists because there is both global storage (main memory) and per-processor local storage (processor caches) implementing the abstraction of a single shared address space.</li>
<li>In a cache hierarchy,<br>L1 and L2 caches are private per core while L3 cahce is shared by cores in the same chip.<br>L3 cache is split into sectors or banks. Each bank is physically associated with a core, but managed hardware-wise as a single coherent unit.<br>L2 cache and L3 cache communicate through a ring interconnect where most inter-processor actions happens. </li>
</ol>
<h2 id="Uniprocessor-case"><a href="#Uniprocessor-case" class="headerlink" title="Uniprocessor case"></a>Uniprocessor case</h2><ol>
<li>On a uniprocessor, providing coherence is fairly simple, since writes typically come from one client: the processor. Load operation must examine all pending stores in store buffer and select the last sequence. </li>
<li>There is one exception on a uniprocessor, which is device I/O via direct memory access (DMA). </li>
<li>One solution to DMA is that CPU writes to shared buffers using uncached stores.<br>Another way is supported by OS which will mark virtual memory pages containing shared buffers as not-cachable, and explicitly flush pages from cache when I/O completes. </li>
<li>In practice, DMA transfers are infrequent compared to CPU loads and stores (so these heavyweight software solutions are acceptable)</li>
</ol>
<h2 id="Coherence-definition"><a href="#Coherence-definition" class="headerlink" title="Coherence definition"></a>Coherence definition</h2><ol>
<li>Obeys program order as expected of a uniprocessor system: A read by processor P to address X that follows a write by P to address X, should return the value of the write by P (assuming no other processor wrote to X in between)</li>
<li>Write propagation: A read by processor P1 to address X that follows a write by processor P2 to X returns the written value, if the read and write are “sufficiently separated” in time (assuming no other write to X occurs in between)</li>
<li>Write serialization: Writes to the same address are serialized: two writes to address X by any two processors are observed in the same order by all processors.</li>
<li>Write propagation means that notification of a write must eventually get to the other processors. Note that precisely when information about the write is propagated is not specified in the definition of coherence.</li>
</ol>
<h1 id="Implementing-choherence"><a href="#Implementing-choherence" class="headerlink" title="Implementing choherence"></a>Implementing choherence</h1><ol>
<li>Software-based solution: OS uses page-fault mechanism to propagate writes. It can be used to implement memory coherence over clusters of workstations</li>
<li>Hardware-based solutions: “snooping”-based coherence implementations and directory-based coherence implementations</li>
<li>Most modern multi-core CPUs implement cache coherence<br>Discrete GPUs do not implement cache coherence. Overhead of coherence deemed not worth it for graphics and scientific computing applications (NVIDIA GPUs provide single shared L2 + atomic memory operations)<br>But the latest Intel Integrated GPUs do implement cache coherence</li>
</ol>
<h2 id="Shared-caches"><a href="#Shared-caches" class="headerlink" title="Shared caches"></a>Shared caches</h2><ol>
<li>One single cache shared by all processors eliminates problem of replicating state in multiple caches and makes coherence easy. </li>
<li>This has obvious scalability problems since the point of a cache is to be local and fast. It also causes interference and contention due to many clients. </li>
<li>Facilitates fine-grained sharing (overlapping working sets). Loads/stores by one processor might pre-fetch lines for another processor</li>
</ol>
<h2 id="Snooping-cache-coherence-schemes"><a href="#Snooping-cache-coherence-schemes" class="headerlink" title="Snooping cache-coherence schemes"></a>Snooping cache-coherence schemes</h2><ol>
<li>Main idea: all coherence-related activity is broadcast to all processors</li>
<li>Cache controllers monitor (“they snoop”) memory operations, and react accordingly to maintain memory coherence</li>
<li>Cache controller must respond to actions from both ends:<br>It must respond the Load/Store requests from its local processor<br>It also must respond coherence-related activity broadcast over the chip’s interconnect. </li>
<li>The interconnect is between memory and caches possessed by each processor. There is not only memory-cache information, but also cache-cache information, which will limit the scality of the system. </li>
</ol>
<h3 id="Write-through-caches"><a href="#Write-through-caches" class="headerlink" title="Write-through caches"></a>Write-through caches</h3><ol>
<li>For the invalidation-based protocol, when one processor write into an address, cache controller broadcasts<br>invalidation message for other caches to mark that line to invalidation.<br>the next read from other processors will trigger cache miss</li>
<li>For the update-based protocol: other caches will update their local copies as the information is sent. </li>
<li>States: Valid (V) or Invalid (I)<br>A local processor read (PrRd) always ends at valid. If the operation starts from an invalid state, a message will be sent (BusRd). If it starts from a valid state, no message will be sent.<br>A local processor write (PrWr) always ends at the same state as before the operation (assumes write no-allocate policy), and always sends a message (BusWr).<br>When a write message from other processor is received (BusWr), It always ends at invalid state.<br><img src="/img/08-Snooping-based-Cache-Coherence-1.jpeg" width="40%"></li>
<li>Requirements of the interconnect:<br>All write transactions visible to all cache controllers.<br>All write transactions visible to all cache controllers in the same order. </li>
<li>Simplifying assumptions here:<br>Interconnect and memory transactions are atomic<br>Processor waits until previous memory operations is complete before issuing next memory operation<br>Invalidation applied immediately as part of receiving invalidation broadcast</li>
</ol>
<h1 id="Write-back-caches-Invalidation-based"><a href="#Write-back-caches-Invalidation-based" class="headerlink" title="Write-back caches (Invalidation-based)"></a>Write-back caches (Invalidation-based)</h1><ol>
<li>Dirty state of cache line now indicates exclusive ownership</li>
<li>Exclusive: cache is only cache with a valid copy of line (it can safely be written to)<br>Owner: cache is responsible for supplying the line to other processors when they attempt to load it from memory (otherwise a load from another processor will get stale data from memory)</li>
<li>A line in the “exclusive” state can be modified without notifying<br>the other caches<br>Processor can only write to lines in the exclusive state. So they need a way to tell other caches that they want exclusive access to the line. They will do this by sending all the other caches messages<br>When cache controller snoops a request for exclusive access to line it contains, it must invalidate the line in its own cache</li>
</ol>
<h2 id="MSI-write-back-invalidation-protocol"><a href="#MSI-write-back-invalidation-protocol" class="headerlink" title="MSI write-back invalidation protocol"></a>MSI write-back invalidation protocol</h2><ol>
<li>Three cache line states:<br>Invalid (I): same as meaning of invalid in uniprocessor cache<br>Shared (S): line valid in one or more caches<br>Modified (M): line valid in exactly one cache (a.k.a. “dirty” or “exclusive” state)</li>
<li>The local processors have the same operations as write-through case.<br>The coherence-related bus transactions from remote caches have three kinds:<br>BusRd: obtain copy of line with no intent to modify<br>BusRdX: obtain copy of line with intent to modify<br>flush: write dirty line out to memory<br><img src="/img/08-Snooping-based-Cache-Coherence-2.png" width="50%"></li>
<li>When try to write an invalid line without reading it, the content of the current modified state line will be sent to the new writer. </li>
<li>Write propagation is achieved via combination of invalidation on BusRdX, and flush from M-state on subsequent BusRd/BusRdX from another processors</li>
<li>Write serialization<br>Writes that appear on interconnect are ordered by the order they appear on interconnect (BusRdX)<br>Reads that appear on interconnect are ordered by order they appear on interconnect (BusRd)<br>Writes that don’t appear on the interconnect (PrWr to line already in M state):<ul>
<li>Sequence of writes to line comes between two interconnect transactions for the line</li>
<li>All writes in sequence performed by same processor, P (that processor certainly observes them in correct sequential order)</li>
<li>All other processors observe notification of these writes only after a interconnect transaction for the line. </li>
<li>So all processors see writes in the same order. </li>
</ul>
</li>
</ol>
<h2 id="MESI-invalidation-protocol"><a href="#MESI-invalidation-protocol" class="headerlink" title="MESI invalidation protocol"></a>MESI invalidation protocol</h2><ol>
<li>MSI requires two interconnect transactions for the common case of reading an address, then writing to it<ul>
<li>Transaction 1: BusRd to move from I to S state</li>
<li>Transaction 2: BusRdX to move from S to M state</li>
</ul>
</li>
<li>Solution: add additional state E (“exclusive clean”) to mark the line that has not been modified, but only this cache has a copy of the line<br>This state decouples exclusivity from line ownership (line not dirty, so copy in memory is valid copy of data)<br>Upgrade from E to M does not require an interconnect transaction </li>
<li><img src="/img/08-Snooping-based-Cache-Coherence-3.jpeg" width="50%"></li>
</ol>
<h2 id="5-stage-invalidation-based-protocol"><a href="#5-stage-invalidation-based-protocol" class="headerlink" title="5-stage invalidation-based protocol"></a>5-stage invalidation-based protocol</h2><ol>
<li>Who should supply data on a cache miss when line is in the E or S state of another cache?<br>Can get cache line data from memory or can get data from another cache? If source is another cache, which one should provide it?</li>
<li>Cache-to-cache transfers add complexity, but commonly used to reduce both latency of data access and reduce memory bandwidth required by application</li>
<li>MESIF: Like MESI, but one cache holds shared line in F state rather than S (F=”forward”). Cache with line in F state services miss<br>Simplifies decision of which cache should service miss (basic MESI: all caches respond)<br>Used by Intel processors</li>
<li>MOESI: Transition from M to O (O=”owned, but not exclusive”) and do not flush to memory (In MESI protocol, transition from M to S requires flush to memory).<br>Other processors maintain shared line in S state, one processor maintains line in O state. Data in memory is stale, so cache with line in O state must service cache misses.<br>Used in AMD Opteron</li>
</ol>
<h1 id="Invalidation-based-vs-Update-based"><a href="#Invalidation-based-vs-Update-based" class="headerlink" title="Invalidation-based vs. Update-based"></a>Invalidation-based vs. Update-based</h1><ol>
<li>Invalidation-based protocol: To write to a line, cache must obtain exclusive access to it. All other caches must invalidate their copies</li>
<li>Update-based protocol: Can write to shared copy by broadcasting update to all other copies</li>
<li>Intuitively, update would seem preferable if other processors<br>sharing data continue to access it after a write occurs<br>But updates are overhead if data just sits in caches (and is never read by another processor again) or application performs many writes before the next read</li>
<li>Update can reduce cache miss rate since all shared copies remain valid.<br>Update can suffer from high traffic due to multiple writes before the next read by another processor</li>
</ol>
<h1 id="Snoop-for-a-cache-hierarchy"><a href="#Snoop-for-a-cache-hierarchy" class="headerlink" title="Snoop for a cache hierarchy"></a>Snoop for a cache hierarchy</h1><ol>
<li>Challenge: changes made to data at L1 cache may not be visible to L2 cache controller than snoops the interconnect. </li>
<li>Inclusion property:<br>All lines in closer to processor cache are also in farther from processor cache. Thus, all transactions relevant to L1 are also relevant to L2, so it is sufficient for only the L2 to snoop the interconnect.<br>If line is in owned state (M in MSI/MESI) in L1, it must also be in owned state in L2. Allows L2 to determine if a bus transaction is requesting a modified cache line in L1 without requiring information from L1. </li>
<li>Even if L2 is larger than L1, the inclusion cannot be maintained automatically. L1 and L2 might choose to evict different lines because the access histories differ. </li>
<li>When line X is invalidated in L2 cache due to BusRdX from another cache. Must also invalidate line X in L1<br>Solution: Each L2 line contains an additional state bit indicating if line also exists in L1. This bit tells the L2 invalidations of the cache line due to coherence traffic need to be propagated to L1. </li>
<li>When L1 write is hit, the corresponding line in L2 cache is in modified state in the coherence protocol, but L2 data is stale.<br>When coherence protocol requires X to be flushed from L2, L2 cache must request the data from L1.<br>Add another bit for “modified-but-stale” (flushing a “modified-but-stale” L2 line requires getting the real data from L1 first.)</li>
</ol>
<h1 id="False-sharing"><a href="#False-sharing" class="headerlink" title="False sharing"></a>False sharing</h1><ol>
<li>Fasle sharing is that two processors write to different addresses, but those addresses map to the same cache line. The cache line keeps invalidating and request data from another processor, generating significant amounts of communication due to the coherence protocol. </li>
<li>We can split the line into two parts and each processor only write one part. </li>
<li>One way is to insert some paddings to make the data written by one processor take up a whole cache line. This can easily implemented in software level. But it causes memory waste. </li>
<li>Another way is mapping addresses handled by the same processor to the same cache line. This causes no waste, but break the successiveness of memory address within a cache line. Also it needs to know the addresses each processor will write, and is harder to implement. </li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2022/06/17/02-Convolution/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2022/06/17/02-Convolution/" class="post-title-link" itemprop="url">02. Convolution</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-06-17 13:25:48" itemprop="dateCreated datePublished" datetime="2022-06-17T13:25:48+08:00">2022-06-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-06-19 18:02:45" itemprop="dateModified" datetime="2022-06-19T18:02:45+08:00">2022-06-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index">
                    <span itemprop="name">计算机科学与技术</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F-MIT-6-007/" itemprop="url" rel="index">
                    <span itemprop="name">信号与系统 (MIT 6.007)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ol>
<li><p>We try to decompose input signal into a linear combination of basic signals that will provide analytical convenience.<br>Normally the analytical convenience means that the output can be easily generated. </p>
</li>
<li><p>Decompose a signal into a linear combination of delayed impulses. And that leads to a representation for linear time-invairant systems, which is referred to as convolution.<br>Another kind is a decomposition of inputs into complex exponentials. That leads to a representation of signals and systems through Fourier analysis. </p>
</li>
<li><p>For a sequence $x[n]$, we can decompose $x[n]=\displaystyle\sum^{+\infty}_{k=-\infty}x[k]\delta[n-k] $. Namely, we can represent $x[n]$ as linear combination of delayed impulse signals $\delta[n-k]$ with coefficients been $x[k]$.<br>In a linear system, we denote $h_k[n] $ as the output when the input is $\delta[n-k]$,  we can have the output when the input is $x[n]$ as $y[n]=\displaystyle\sum^{+\infty}_{k=-\infty}x[k]h_k[n] $.<br>In addition, if the system is time-invariant, $h_k[n]=\delta(n-k)=\delta(n-k-0)=h_0[n-k] $. Define $h_0[n]=h[n]$ to get $y[n]=\displaystyle\sum^{+\infty}_{k=-\infty}x[k]h[n-k] $ in the form of convolution sum denoted by $y[n]=x[n]\ast h[n] $. </p>
</li>
<li><p>In continuous case, we want to represent $x(t)$ with successive rectangles and see each rectangle as an impulse. As the width of each rectangle goes narrower and narrower, the representation becomes more accurate.<br>For a rectangle in $(t_0,t_0+\Delta)$, the height of the rectangle depends on $x(t_0)$. We can represent the the impulse as $x(t_0)\delta_\Delta(t-t_0)\Delta$ where $\delta_\Delta(t)$ is defined as before.<br>Now, $x(t)$ is the sum of all impulses, $x(t)\cong\displaystyle\sum^{+\infty}_{k=-\infty}x(k\Delta)\delta_\Delta(t-k\Delta)\Delta $.  $x(t)=\displaystyle\lim_{\Delta\to0}\sum^{+\infty}_{k=-\infty}x(k\Delta)\delta_\Delta(t-k\Delta)\Delta=\int^{+\infty}_{-\infty}x(\tau)\delta(t-\tau)d\tau $. </p>
</li>
<li><p>In $x(t)=\displaystyle\lim_{\Delta\to0}\sum^{+\infty}_{k=-\infty}x(k\Delta)\delta_\Delta(t-k\Delta)\Delta $, we can see it as the linear combination of $\delta_\Delta(t-k\Delta)$ with coefficient been $x(k\Delta)\Delta $.<br>In a linear system, if the output of $\delta_\Delta(t-k\Delta)$ is $h_{k\Delta}(t)$, we can know that the output $x(t)$ is $y(t)=\displaystyle\lim_{\Delta\to0}\sum^{+\infty}_{k=-\infty}x(k\Delta)h_{k\Delta}(t)\Delta=\int^{+\infty}_{-\infty}x(\tau)h_\tau(t)d\tau $.<br>In addition, if the system is time-invariant, $h_\tau(t)=h_0(t-\tau)$, and $y(t)=\displaystyle\int^{+\infty}_{-\infty}x(\tau)h(t-\tau)d\tau $ in the form of convolution integral denoted by $y(t)=x(t)\ast h(t)$. </p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2022/06/12/01-Signals-and-Systems/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2022/06/12/01-Signals-and-Systems/" class="post-title-link" itemprop="url">01. Signals and Systems</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-06-12 16:53:56" itemprop="dateCreated datePublished" datetime="2022-06-12T16:53:56+08:00">2022-06-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-06-20 22:54:46" itemprop="dateModified" datetime="2022-06-20T22:54:46+08:00">2022-06-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index">
                    <span itemprop="name">计算机科学与技术</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F-MIT-6-007/" itemprop="url" rel="index">
                    <span itemprop="name">信号与系统 (MIT 6.007)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Sinusoidal-signals"><a href="#Sinusoidal-signals" class="headerlink" title="Sinusoidal signals"></a>Sinusoidal signals</h1><h2 id="Continuous-time"><a href="#Continuous-time" class="headerlink" title="Continuous-time"></a>Continuous-time</h2><ol>
<li><p>$x(t)=A cos(\omega_0t+\phi)$. Here $A$ stands for amplitude, $\omega_0$ stands for frequency, and $\phi$ stands for phase. </p>
</li>
<li><p>A sinusoidal signal has period $T_0=\frac{2\pi}{\omega_0}$. </p>
</li>
<li><p>Time shift corresponds to a phase change, while phase change, likewise, corresponds to time shift.<br>For a time shift $\Delta t$, we can always have a phase change $\Delta\phi$, so that $x(t+\Delta t) = Acos(\omega_0(t+\Delta t)+\phi)=Acos(\omega_0t+\omega_0\Delta t+\phi)\Rightarrow\Delta\phi=\omega_0\Delta t$, and $\Delta t=\frac{\Delta\phi}{\omega_0}$</p>
</li>
<li><p>When $\phi=0$, $x(t)$ is a cosine signal, which is even. Namely, $x(t)=x(-t)$,<br>When $\phi=-\frac{\pi}{2}$, $x(t)=Acos(\omega_0t-\frac{\pi}{2})=Asin(\omega_0t)=Acos(\omega(t-\frac{T_0}{4})$ is a sinusoid signal, which is odd. Namely $x(t)=-x(-t)$. </p>
</li>
</ol>
<h2 id="Discrete-time"><a href="#Discrete-time" class="headerlink" title="Discrete-time"></a>Discrete-time</h2><ol>
<li><p>$x[n]=A cos(\Omega_0n+\phi)$. Here $A$ stands for amplitude, $\Omega_0$ stands for frequency, and $\phi$ stands for phase. $n$ only takes the integer values. </p>
</li>
<li><p>A time shift corresponds to a phase change. $x[t+\Delta t]=Acos(\Omega_0(t+\Delta t))=Acos(\Omega_0t+\Omega_0\Delta t)$. Hence $\Delta\phi=\Omega_0\Delta t$<br>However, not any phase change can be interpreted as a simple time shift in the sequence. A constraint in discrete-time is that $t+\Delta t$ must be an integer, but $\Delta t=\frac{\Delta\phi}{\Omega_0}$ cannot guarantee that. </p>
</li>
<li><p>If we want $x[n]$ to be periodic, $x[n]=x[n+N]\Rightarrow Acos(\Omega_0n+\phi)=Acos(\Omega_0n+\Omega_0N+\phi)\Rightarrow \Omega_0N=2\pi m$ with $m$ being an integer.<br>So when there exists an $m$ to make $\frac{2\pi m}{\Omega_0}$ an integer, $x[n]$ is periodic, and  the period $N_0=\frac{2\pi m}{\Omega_0}$.  Namely $\frac{2\pi}{\Omega_0}$ must be rational. </p>
</li>
<li><p>$Acos((\Omega_0+\Delta\Omega)n+\phi)=Acos((\Omega_0n+\Delta\Omega n+\phi))$. So for $\Delta\Omega=2\pi k$, $x[n]=x’[n]$. Thus, in discrete-time case, this class of signals is identical signals for values of $\Omega_0$ separated by $2\pi$.<br>In continuous-time signal, all signals with different $\Omega_0$ have distinct values. </p>
</li>
</ol>
<h1 id="Exponentials"><a href="#Exponentials" class="headerlink" title="Exponentials"></a>Exponentials</h1><h2 id="Real-exponentials"><a href="#Real-exponentials" class="headerlink" title="Real exponentials"></a>Real exponentials</h2><ol>
<li><p>In the continuous-time case, $x(t)=Ce^{at}$ with $C$ and $a$ both being real numbers. When $a&gt;0$, $x(t)$ is geomatically growing. When $a&lt;0$, $x(t)$ is decaying.<br>A time shift corresponds to a scale change, vise versa. $x(t+\Delta t)=Ce^{a(t+\Delta t)}=Ce^{a\Delta t}e^{at}$</p>
</li>
<li><p>In the discrete-time case, $x[n]=Ce^{\beta n}=C\alpha^n$, with $C,\alpha$ being real number. </p>
</li>
<li><p>When $\alpha&gt;1$, $x[n]$ is growing. When $0&lt;\alpha&lt;1$, $x[n]$ is decaying.<br>When $\alpha&lt;0$, $\beta$ is an imaginary number, and the sequence is going to alternate between positive and negative. </p>
</li>
</ol>
<h2 id="Complex-exponentials"><a href="#Complex-exponentials" class="headerlink" title="Complex exponentials"></a>Complex exponentials</h2><ol>
<li><p>In continuous-time case, $C$ and $a$ are complex numbers. We write $C$ in polar form $C=|C|e^{j\theta}$ and $a$ in rectangular form $a=r+j\omega_0$.<br>$x(t)=|C|e^{j\theta}e^{(r+j\omega_0)t}=|C|e^{rt}e^{j(\omega_0t+\theta)}=|C|e^{rt}cos(\omega_0t+\theta)+j|C|e^{rt}sin(\omega_0t+\theta)$</p>
</li>
<li><p>In discrete-time case, we write $C$ and $\alpha$ both in polar form $C=|C|e^{j\theta},\alpha=|\alpha|e^{j\Omega_0}$.<br>$x[n]=|C|e^{j\theta}(|\alpha|e^{j\Omega_0})^n=|C||\alpha|^ne^{j(\Omega_0n+\theta)}=|C||\alpha|^ncos(\Omega_0n+\theta)+j|C||\alpha|^nsin(\Omega_0n+\theta)$</p>
</li>
<li><p>When $r=0$, $x(t)$ is always periodic. When $\alpha=1$, whether $x[n]$ is periodic depends on $\Omega_0$. </p>
</li>
</ol>
<h1 id="Unit-step-and-unit-impuls-signals"><a href="#Unit-step-and-unit-impuls-signals" class="headerlink" title="Unit step and unit impuls signals"></a>Unit step and unit impuls signals</h1><h2 id="Discrete-time-1"><a href="#Discrete-time-1" class="headerlink" title="Discrete-time"></a>Discrete-time</h2><ol>
<li><p>For unit step sequence, $u[n]=\left\{ \begin{matrix}0 &amp; n&lt;0\\1 &amp; n≥0  \end{matrix} \right.$</p>
</li>
<li><p>For unit impulse sequence, $\delta[n]=\left\{\begin{matrix}0 &amp; n≠0\\1 &amp; n=0 \end{matrix}\right.$</p>
</li>
<li><p>We can express the unit impulse with unit step. $\delta[n]=u[n]-u[n-1] $. Namely, the unit impulse equals to the unit step minus unit step delayed, which is the first difference. </p>
</li>
<li><p>We can also express the unit step with unit impulse. $u[n]=\displaystyle\sum^n_{m=-\infty}\delta[m] $ or $u[n]=\displaystyle\sum^\infty_{k=0}\delta[n-k] $</p>
</li>
</ol>
<h2 id="Continuous-time-1"><a href="#Continuous-time-1" class="headerlink" title="Continuous-time"></a>Continuous-time</h2><ol>
<li><p>For unit step function, $u(t)=\left\{\begin{matrix}0 &amp; t &lt; 0\\1 &amp; t &gt; 0 \end{matrix} \right. $.<br>The unit step function is discontinuous at $t=0$. So in effect, we need to think the unit step function as the limit of a continuous function, $u_\Delta(t) $ linearly increase from $0$ to $1$ at time $t$ from $0$ to $\Delta$. Thus $u(t)=u_\Delta(t) $ as $\Delta\to0$. </p>
</li>
<li><p>Unit impulse function is the derivative of unit step function, $\delta(t)=\frac{du(t)}{dt} $.<br>But $u(t)$ is discontinuous, so we would consider $\delta_\Delta(t)$ as the derivative of $u_\Delta(t)$, $\delta_\Delta(t)=\frac{du_\Delta(t)}{dt} $. So $\delta(t)=\delta_\Delta(t) $ as $\Delta\to0$.<br>$\delta_\Delta(t)=\left\{\begin{matrix}\frac{1}\Delta&amp;0&lt;t&lt;\Delta\\0&amp;otherwise \end{matrix} \right.$. As $\Delta\to0$, the width of the rectangle decreases while the height increases, and the area remains $1$.<br>We can draw $\delta(t)$ by an arrow point to the positive size of y-axis with length of $1$.<br>Since $\displaystyle\lim_{\Delta\to0}u_\Delta(t)=u(t)$, $\displaystyle\lim_{\Delta\to0}\delta_\Delta(t)=\delta(t)$</p>
</li>
<li><p>The relationship from unit impulse to unit step is derivative. And, natually, the relationship from unit step to unit impulse is integral, $u(t)=\displaystyle\int^t_{-\infty}\delta(t)dt$</p>
</li>
</ol>
<h1 id="Systems"><a href="#Systems" class="headerlink" title="Systems"></a>Systems</h1><ol>
<li><p>Systems take one signal as its input, and output another signal.<br>For continuous-time system denoted by $x(t)\to y(t)$, both signals are continuous.<br>For discrete-time system denoted by $x[n]\to y[n]$, both signals are discrete. </p>
</li>
<li><p>A cascade of systems (a series interconnection systems): taking the output of one system as the input of another system. </p>
</li>
<li><p>Parallel interconnection system: inputs are feed into two systems simultaneously. And the output of those two systems are added together to give the overall system output. </p>
</li>
<li><p>Feedback interconnection system: the output of system 1 is the output of the overall system. The output also is fed into system 2. And the sum of output of system 2 and the overall input of the system is the input of system 1. </p>
</li>
<li><p>Memoryless: the output at a certain time only depends on the input of the same time.<br>The unit delay system $y[n]=x[n-1] $ is not a memoryless system. </p>
</li>
<li><p>Invertibility: given the output, you can figure out the unique input that cause the output.<br>Identity system is the cascade of a system and its inverse. The inverse of system $A$ is denoted by $A^{-1}$<br>The inverse of an integrator is a differentiator. But a differentiator is not invertible, for the input of a given output is not unique. </p>
</li>
<li><p>Causality: output at any time depends only on input prior or equal to that time. Or system cannot anticipate future inputs.<br>For $x_1(t)\to y_1(t) $ and $x_2(t)\to y_2(t) $, if $x_1(t)$ and $x_2(t)$ are the same util some time, then $y_1(t)$ and $y_2(t)$ are alse the same util the same time. </p>
</li>
<li><p>Stability: for every bounded input, the output is bounded.<br>An unstable system can be stablized through feadback. Feadback can also destablize a system. </p>
</li>
<li><p>Time-invariable: If $x(t)\to y(t) $, then $x(t-t_0)\to y(t-t_0) $.<br>The system doesn’t care what happened at the origin. If the input is shifted by a certain time, the output is also shifted by the same time. </p>
</li>
<li><p>Linearity: For two systems $x_1(t)\to y_1(t) $ and $x_2(t)\to y_2(t) $, then $ax_1(t)+bx_2(t)\to ay_1(t)+by_2(t) $. </p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://http//www.laughingtree.cn/2022/06/11/07-Workload-driven-Perfromance-Evaluation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="LiyunZhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaughingTree">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2022/06/11/07-Workload-driven-Perfromance-Evaluation/" class="post-title-link" itemprop="url">07. Workload-driven Perfromance Evaluation</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-06-11 21:39:38" itemprop="dateCreated datePublished" datetime="2022-06-11T21:39:38+08:00">2022-06-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-06-12 16:26:27" itemprop="dateModified" datetime="2022-06-12T16:26:27+08:00">2022-06-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index">
                    <span itemprop="name">计算机科学与技术</span>
                  </a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-CMU-15-418-Stanford-CS149/" itemprop="url" rel="index">
                    <span itemprop="name">并行计算 (CMU 15-418 / Stanford CS149)</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>We should compare parallel program speedup to the best sequential program, instead of parallel algorithm running on one core.<br>The reason is that to allow for parallelism, we might change the algorithm, and make it slower when executed sequentially.</p>
<h1 id="Scaling"><a href="#Scaling" class="headerlink" title="Scaling"></a>Scaling</h1><h2 id="Why-consider-scaling"><a href="#Why-consider-scaling" class="headerlink" title="Why consider scaling?"></a>Why consider scaling?</h2><ol>
<li><p>Arithmetic intensity is determined by both problem size and the processors number. Small problem size or large processor number both yields low arithmetic intensity.</p>
</li>
<li><p>If the problem size is too small, it might already execute fast enough on a single core. Scaling the performance of small problem may not be all that important.<br>Parallelism overheads dominate parallelism benefits, and may even result in slow downs. </p>
</li>
<li><p>If the problem size is too large for a single machine, working set may not fit in memory, and causing thrashing to disk. With enough processors, the key working set fits in per-processor cache.<br>This may get a super-linear speedup and make speedup on a bigger parallel machine with more memory look amazing. </p>
</li>
<li><p>Another situation that we might get a super-linear speedup is when we try to search for a solution. With parallelism, we are trying more different variance of search, and more likely to find the solution earlier. </p>
</li>
<li><p>So we shouldn’t only consider a fixed problem size. Instead, it is desirable to scale problem size as machine sizes grow. </p>
</li>
<li><p>In architecture, scaling up considers how does performance scale with increasing core count, and will design scale to the high end?<br>Scaling down considers how does performance scale with decreasing core count, and will desing scale to the low end? </p>
</li>
</ol>
<h2 id="Different-scalings"><a href="#Different-scalings" class="headerlink" title="Different scalings"></a>Different scalings</h2><ol>
<li><p>Strong scaling: scaling processors with a fixed problem size. Consider the ratio between the runtime of problem $X$ on $P$ processors and the runtime $X$ on $1$ processor. </p>
</li>
<li><p>The goal ratio is $P$. This kind of scaling tells us does having more processors get job done faster?</p>
</li>
<li><p>Weak scaling: scaling problem size and processors proportionally. Consider the ratio of the runtime of problem $P\times X$ on $P$ processors and the runtime of problem $X$ on $1$ processor. </p>
</li>
<li><p>The goal ratio is $1$. This kind of scaling tells us does having more procesors let me do bigger jobs? </p>
</li>
<li><p>Problem size is often determined by more than one parameter. So in weak scaling, we need to consider how should the parameter be changed. </p>
</li>
</ol>
<h2 id="Scaling-constrains"><a href="#Scaling-constrains" class="headerlink" title="Scaling constrains"></a>Scaling constrains</h2><ol>
<li><p>When scaling a probelm, we should first ask that in my situation, under what constraints should the problem be scaled? </p>
</li>
<li><p>Problem-constrained scaling focuses on using a parallel computer to solve the same problem faster<br>Speedup $=\frac{time 1 processor}{time P processors}$</p>
</li>
<li><p>Time-constrained scaling focuses on completing more work in a fixed amount of time<br>Speedup $ = \frac{work done by P processors}{work done by 1 processor}$</p>
</li>
<li><p>“Work done” may not be linear function of problem inputs. One approach of defining “work done” is by execution time of same computation on a single processor (but consider effects of thrashing if problem too big)</p>
</li>
<li><p>Ideally, a measure of work is simple to understand and scales linearly with sequential run time (So ideal speedup remains linear in $P$)</p>
</li>
<li><p>Memory-constrained scaling (weak scaling) focuses on running the largest problem possible without overflowing main memory. Neither work or execution times are held constant.<br>Speedup $= \frac{work (P processors)}{time (P processors)}/\frac{work (1 processor)}{time (1 processor)}=\frac{work per unit time on P processors}{work per unit time on 1 processor}<br>$There are two assumptions: memory resources scale with processor count, and spilling to disk is infeasible behavior. </p>
</li>
</ol>
<h2 id="Challenges-of-scaling-down-or-up"><a href="#Challenges-of-scaling-down-or-up" class="headerlink" title="Challenges of scaling down or up"></a>Challenges of scaling down or up</h2><ol>
<li><p>Preserve ratio of time spent in different program phases. </p>
</li>
<li><p>Preserve important behavioral characteristics. </p>
</li>
<li><p>Preserve contention and communication patterns. Tough to preserve contention since contention is a function of timing and ratios. </p>
</li>
<li><p>Preserve scaling relationships between problem parameters. </p>
</li>
</ol>
<h1 id="Simulation"><a href="#Simulation" class="headerlink" title="Simulation"></a>Simulation</h1><ol>
<li><p>Architects evaluate architectural decisions quantitatively using<br>hardware performance simulators. </p>
</li>
<li><p>Architect runs simulations with new feature, runs simulations without new feature, compare simulated performance. Or simulate against a wide collection of benchmarks. </p>
</li>
<li><p>You can design detailed simulator to test new architectural feature. It would be very expensive to simulate a parallel machine in full detail.<br>Often cannot simulate full machine configurations or realistic problem sizes (must scale down workloads significantly). Architects need to be confident scaled down simulated results predict reality</p>
</li>
<li><p>In trace-driven simulator, we instrument real code running on real machine to record a trace of all memory accesses. Then play back trace on simulator.<br>It may lead to overfit the trace you have instead of having a better generalization. </p>
</li>
<li><p>In execution-driven simulator, we execute simulated program in software. Simulated processors generate memory references, which are processed by the simulated memory hierarchy.<br>Performance of simulator is typically inversely proportional to level of simulated detail. </p>
</li>
<li><p>When dealing with large parameter space of machines (number of processors, cache sizes, cache line sizes, memory bandwidths, etc. ), we can use the architectural simulation state space. </p>
</li>
</ol>
<h1 id="Understanding-the-performance"><a href="#Understanding-the-performance" class="headerlink" title="Understanding the performance"></a>Understanding the performance</h1><ol>
<li><p>Always, always, always try the simplest parallel solution first, then measure performance to see where you stand.</p>
</li>
<li><p>Determine if your performance is limited by computation, memory bandwidth (or memory latency), or synchronization?<br>Try and establish “high watermarks”. What’s the best you can do in practice? How close is your implementation to a best-case scenario?</p>
</li>
<li><p>Roofline model: Use microbenchmarks to compute peak performance of a machine as a function of arithmetic intensity of application. Then compare application’s performance to known peak values. </p>
</li>
<li><p>The x-axis means operational intensity (like Flops/Byte), and the y-axis means attenable GFlops/s.<br>In the diagonal region, the y grows with x, which means the memory bendwidth is limited. In the horizontal region, the y stays the same as x grows, which means the compute is limited. </p>
</li>
<li><p>When compute is limited, we can make use of ILP or SIMD, or balance floating-point.<br>When memory bandwidth is limited, we can limit accesses to unit stride accesses only, develope memory affinity, or use software prefetching. </p>
</li>
</ol>
<h2 id="Establish-high-watermarks"><a href="#Establish-high-watermarks" class="headerlink" title="Establish high watermarks"></a>Establish high watermarks</h2><ol>
<li><p>Add “math” (non-memory instructions).<br>Does execution time increase linearly with operation count as math is added? If so, this is evidence that code is instruction-rate limited</p>
</li>
<li><p>Remove almost all math, but load same data.<br>How much does execution-time decrease? If not much, suspect memory bottleneck</p>
</li>
<li><p>The first two way need to avoid compiler optimization. </p>
</li>
<li><p>Change all array accesses to A[0].<br>How much faster does your code get?<br>This establishes an upper bound on benefit of improving locality of data access</p>
</li>
<li><p>Remove all atomic operations or locks.<br>How much faster does your code get? (provided it still does approximately the same amount of work)<br>This establishes an upper bound on benefit of reducing sync overhead.</p>
</li>
</ol>
<h2 id="Profilers-performance-monitoring-tools"><a href="#Profilers-performance-monitoring-tools" class="headerlink" title="Profilers/performance monitoring tools"></a>Profilers/performance monitoring tools</h2><ol>
<li><p>All modern processors have low-level event “performance counters”, which are registers that count important details such as: instructions completed, clock ticks, L2/L3 cache hits/misses, bytes read from memory controller, etc. </p>
</li>
<li><p>Intel’s Performance Counter Monitor Tool provides a C++ API for accessing these registers. </p>
</li>
<li><p>It can use <code>getIPC(begin, end)</code>, <code>getL3CacheHitRatio(begin, end)</code>, <code>getBytesReadFromMC(begin, end)</code>, etc. to get values of those information. </p>
</li>
<li><p>The <code>begin</code> and <code>end</code> is a <code>SystemCountState</code> instance acquired by <code>getSystemCounterState()</code> at the beginning and end of the code to analyze. </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">PCM *m = PCM::getInstance();</span><br><span class="line">SystemCounterState begin = getSystemCounterState();</span><br><span class="line"></span><br><span class="line"><span class="comment">// code to analyze goes here</span></span><br><span class="line"></span><br><span class="line">SystemCounterState end = getSystemCounterState();</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(“Instructions per clock: %f\n”, getIPC(begin, end));</span><br><span class="line"><span class="built_in">printf</span>(“L3 cache hit ratio: %f\n”, getL3CacheHitRatio(begin, end));</span><br><span class="line"><span class="built_in">printf</span>(“Bytes read: %d\n”, getBytesReadFromMC(begin, end));</span><br></pre></td></tr></table></figure>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/23/">23</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="LiyunZhang"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">LiyunZhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">227</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">33</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liyun Zhang</span>
</div>
<div class="BbeiAn-info">
       浙ICP备 -
    <a target="_blank" href="http://www.miitbeian.gov.cn/" style="color:#ffffff"  rel="nofollow">19047088号-1</a> <!--a标签中增加nofollow属性，避免爬虫出站。-->|
    <a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=33011802001835" style="color:#ffffff;text-decoration:none;padding-left:30px;background:url(https://s1.ax1x.com/2018/09/29/ilmwIH.png) no-repeat left center" rel="nofollow">浙公网安备 33011802001835号</a>      <!--这里将图标作为了背景，以使得能和后面的文字在同一行-->

</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

</body>
</html>
